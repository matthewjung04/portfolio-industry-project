{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1851811,"sourceType":"datasetVersion","datasetId":1101477}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:39:17.636554Z","iopub.execute_input":"2024-11-05T01:39:17.636992Z","iopub.status.idle":"2024-11-05T01:39:17.652524Z","shell.execute_reply.started":"2024-11-05T01:39:17.636953Z","shell.execute_reply":"2024-11-05T01:39:17.651251Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-reviews-2018-full-dataset/amazon_reviews.csv\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import re\nimport nltk\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag, word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Ensure stopwords are downloaded\nnltk.download(\"stopwords\")\nnltk.download(\"averaged_perceptron_tagger\")\nnltk.download(\"punkt\")\nstop_words = set(stopwords.words(\"english\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:39:17.654567Z","iopub.execute_input":"2024-11-05T01:39:17.654982Z","iopub.status.idle":"2024-11-05T01:40:17.775484Z","shell.execute_reply.started":"2024-11-05T01:39:17.654934Z","shell.execute_reply":"2024-11-05T01:40:17.774294Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n[nltk_data]     [Errno -3] Temporary failure in name resolution>\n[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-reviews-2018-full-dataset/amazon_reviews.csv',)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:17.776937Z","iopub.execute_input":"2024-11-05T01:40:17.777365Z","iopub.status.idle":"2024-11-05T01:40:33.066022Z","shell.execute_reply.started":"2024-11-05T01:40:17.777326Z","shell.execute_reply":"2024-11-05T01:40:33.064820Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"df['rating'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.069168Z","iopub.execute_input":"2024-11-05T01:40:33.069688Z","iopub.status.idle":"2024-11-05T01:40:33.090288Z","shell.execute_reply.started":"2024-11-05T01:40:33.069633Z","shell.execute_reply":"2024-11-05T01:40:33.089110Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"rating\n5.0    379783\n4.0     73303\n3.0     40639\n1.0     34021\n2.0     23413\nName: count, dtype: int64"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.092061Z","iopub.execute_input":"2024-11-05T01:40:33.092575Z","iopub.status.idle":"2024-11-05T01:40:33.116823Z","shell.execute_reply.started":"2024-11-05T01:40:33.092511Z","shell.execute_reply":"2024-11-05T01:40:33.115558Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"               userName  verified  \\\n0       Amazon Customer      True   \n1                 Carla      True   \n2                Jaclyn      True   \n3          Christinne M     False   \n4                 Sandy      True   \n5              Karli S.      True   \n6               patrick      True   \n7              Craig S.      True   \n8           Super Sanne      True   \n9  Matthew Daviskavitch      True   \n\n                                            itemName  \\\n0  Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...   \n1  Prince of Peace Organic Tea, Oolong, 100 Tea Bags   \n2  Pet Champion Adjustable No-Pull Harness, Colla...   \n3  Koh-I-Noor Progresso Woodless Colored 24-Penci...   \n4  Parker Urban Premium Ebony Metal Chiseled, Bal...   \n5  Merrick Whole Earth Farms Adult Recipe Dry Dog...   \n6  Blue Buffalo Life Protection Formula Natural P...   \n7  Squishy Face Studio Flirt Pole V2 with Braided...   \n8                 Penn Plax Net Breeder for Aquarium   \n9  PetSafe Freedom Aluminum Patio Panel Sliding G...   \n\n                                         description  \\\n0  [\"Made from deliciously decadent ingredients, ...   \n1  ['Prince of Peace Enterprises, Inc., founded i...   \n2  [\"The Pet Champion Large/ Extra Large 22-36 in...   \n3  ['Koh-I-Noor Progresso Woodless Colored 24-Pen...   \n4  [\"Stunning craftsmanship based on a classic st...   \n5  ['Merrick Whole Earth Farms is a nutritious do...   \n6  ['Because puppyhood is such an important stage...   \n7  [\"Want An Easy Way To Keep Your Dog Happy And ...   \n8  ['The Net Breeder by Penn Plax is the safe way...   \n9  [\"The Pet Safe Freedom Patio Panel Pet Door al...   \n\n                                               image                brand  \\\n0  ['https://images-na.ssl-images-amazon.com/imag...            Toblerone   \n1  ['https://images-na.ssl-images-amazon.com/imag...      Prince Of Peace   \n2  ['https://images-na.ssl-images-amazon.com/imag...         Pet Champion   \n3  ['https://images-na.ssl-images-amazon.com/imag...           KOH-I-NOOR   \n4  ['https://images-na.ssl-images-amazon.com/imag...               Parker   \n5  ['https://images-na.ssl-images-amazon.com/imag...              Merrick   \n6  ['https://images-na.ssl-images-amazon.com/imag...         Blue Buffalo   \n7  ['https://images-na.ssl-images-amazon.com/imag...  Squishy Face Studio   \n8  ['https://images-na.ssl-images-amazon.com/imag...            Penn Plax   \n9  ['https://images-na.ssl-images-amazon.com/imag...              PetSafe   \n\n                                             feature  \\\n0                                                 []   \n1                                                 []   \n2  ['Features Bright Pink Lemonade pattern', 'Dua...   \n3  ['Rich, pigmented, solid color encased in lacq...   \n4  ['Ebony black with metallic highlights and a g...   \n5  ['Natural ingredients with added vitamins and ...   \n6  ['HIGH QUALITY PUPPY FOOD: Blue Buffalo always...   \n7  ['New and improved V2 developed using customer...   \n8  ['ISOLATE THE FRY: the Net Breeder Deluxe is t...   \n9  ['PERFECT FOR RENTALS: Great for apartments or...   \n\n                   category    price  rating  reviewTime  \\\n0              Prime_Pantry    $1.63     5.0  2018-01-01   \n1  Grocery_and_Gourmet_Food    $6.40     5.0  2018-01-01   \n2              Pet_Supplies    $7.99     5.0  2018-01-01   \n3    Arts_Crafts_and_Sewing   $14.18     5.0  2018-01-01   \n4           Office_Products      NaN     5.0  2018-01-01   \n5              Pet_Supplies      NaN     2.0  2018-01-01   \n6              Pet_Supplies   $28.99     5.0  2018-01-01   \n7              Pet_Supplies   $31.38     3.0  2018-01-01   \n8              Pet_Supplies    $5.49     2.0  2018-01-01   \n9              Pet_Supplies  $164.76     1.0  2018-01-01   \n\n                                             summary  \\\n0                                         Five Stars   \n1                                         Five Stars   \n2  she has an odd shape chest and her pull over h...   \n3                                           Loving!!   \n4                                    I love this pen   \n5                                          No Bueno.   \n6  ... and has had no problems with this food - B...   \n7                                 I like the product   \n8                                Not worth the money   \n9                                           One Star   \n\n                                          reviewText  vote  \n0           super smooth and yummy with crunchy bits     0  \n1                               Perfect for kombucha     0  \n2  Finally a harness that fits my puppy. I really...     0  \n3  I LOVE THEM!! I bought them at Micheals our of...     0  \n4  I love this pen! I love the shape of it, the f...     0  \n5  We accidentally purchased this instead of our ...     0  \n6  My 1 year old husky loves it - healthy and has...     0  \n7  I like the product, but am sorry that I purcha...     0  \n8  Very flimsy and cheaply made. We bought 2 and ...     0  \n9  Came with parts missing (door cover, latch and...     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userName</th>\n      <th>verified</th>\n      <th>itemName</th>\n      <th>description</th>\n      <th>image</th>\n      <th>brand</th>\n      <th>feature</th>\n      <th>category</th>\n      <th>price</th>\n      <th>rating</th>\n      <th>reviewTime</th>\n      <th>summary</th>\n      <th>reviewText</th>\n      <th>vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amazon Customer</td>\n      <td>True</td>\n      <td>Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...</td>\n      <td>[\"Made from deliciously decadent ingredients, ...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Toblerone</td>\n      <td>[]</td>\n      <td>Prime_Pantry</td>\n      <td>$1.63</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>super smooth and yummy with crunchy bits</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carla</td>\n      <td>True</td>\n      <td>Prince of Peace Organic Tea, Oolong, 100 Tea Bags</td>\n      <td>['Prince of Peace Enterprises, Inc., founded i...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Prince Of Peace</td>\n      <td>[]</td>\n      <td>Grocery_and_Gourmet_Food</td>\n      <td>$6.40</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>Perfect for kombucha</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jaclyn</td>\n      <td>True</td>\n      <td>Pet Champion Adjustable No-Pull Harness, Colla...</td>\n      <td>[\"The Pet Champion Large/ Extra Large 22-36 in...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Pet Champion</td>\n      <td>['Features Bright Pink Lemonade pattern', 'Dua...</td>\n      <td>Pet_Supplies</td>\n      <td>$7.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>she has an odd shape chest and her pull over h...</td>\n      <td>Finally a harness that fits my puppy. I really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christinne M</td>\n      <td>False</td>\n      <td>Koh-I-Noor Progresso Woodless Colored 24-Penci...</td>\n      <td>['Koh-I-Noor Progresso Woodless Colored 24-Pen...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>KOH-I-NOOR</td>\n      <td>['Rich, pigmented, solid color encased in lacq...</td>\n      <td>Arts_Crafts_and_Sewing</td>\n      <td>$14.18</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Loving!!</td>\n      <td>I LOVE THEM!! I bought them at Micheals our of...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sandy</td>\n      <td>True</td>\n      <td>Parker Urban Premium Ebony Metal Chiseled, Bal...</td>\n      <td>[\"Stunning craftsmanship based on a classic st...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Parker</td>\n      <td>['Ebony black with metallic highlights and a g...</td>\n      <td>Office_Products</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>I love this pen</td>\n      <td>I love this pen! I love the shape of it, the f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Karli S.</td>\n      <td>True</td>\n      <td>Merrick Whole Earth Farms Adult Recipe Dry Dog...</td>\n      <td>['Merrick Whole Earth Farms is a nutritious do...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Merrick</td>\n      <td>['Natural ingredients with added vitamins and ...</td>\n      <td>Pet_Supplies</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2018-01-01</td>\n      <td>No Bueno.</td>\n      <td>We accidentally purchased this instead of our ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>patrick</td>\n      <td>True</td>\n      <td>Blue Buffalo Life Protection Formula Natural P...</td>\n      <td>['Because puppyhood is such an important stage...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Blue Buffalo</td>\n      <td>['HIGH QUALITY PUPPY FOOD: Blue Buffalo always...</td>\n      <td>Pet_Supplies</td>\n      <td>$28.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>... and has had no problems with this food - B...</td>\n      <td>My 1 year old husky loves it - healthy and has...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Craig S.</td>\n      <td>True</td>\n      <td>Squishy Face Studio Flirt Pole V2 with Braided...</td>\n      <td>[\"Want An Easy Way To Keep Your Dog Happy And ...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Squishy Face Studio</td>\n      <td>['New and improved V2 developed using customer...</td>\n      <td>Pet_Supplies</td>\n      <td>$31.38</td>\n      <td>3.0</td>\n      <td>2018-01-01</td>\n      <td>I like the product</td>\n      <td>I like the product, but am sorry that I purcha...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Super Sanne</td>\n      <td>True</td>\n      <td>Penn Plax Net Breeder for Aquarium</td>\n      <td>['The Net Breeder by Penn Plax is the safe way...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>Penn Plax</td>\n      <td>['ISOLATE THE FRY: the Net Breeder Deluxe is t...</td>\n      <td>Pet_Supplies</td>\n      <td>$5.49</td>\n      <td>2.0</td>\n      <td>2018-01-01</td>\n      <td>Not worth the money</td>\n      <td>Very flimsy and cheaply made. We bought 2 and ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Matthew Daviskavitch</td>\n      <td>True</td>\n      <td>PetSafe Freedom Aluminum Patio Panel Sliding G...</td>\n      <td>[\"The Pet Safe Freedom Patio Panel Pet Door al...</td>\n      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n      <td>PetSafe</td>\n      <td>['PERFECT FOR RENTALS: Great for apartments or...</td>\n      <td>Pet_Supplies</td>\n      <td>$164.76</td>\n      <td>1.0</td>\n      <td>2018-01-01</td>\n      <td>One Star</td>\n      <td>Came with parts missing (door cover, latch and...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.118288Z","iopub.execute_input":"2024-11-05T01:40:33.118640Z","iopub.status.idle":"2024-11-05T01:40:33.128252Z","shell.execute_reply.started":"2024-11-05T01:40:33.118603Z","shell.execute_reply":"2024-11-05T01:40:33.127150Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(551159, 14)"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"cols = df.columns\ncols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.129865Z","iopub.execute_input":"2024-11-05T01:40:33.130233Z","iopub.status.idle":"2024-11-05T01:40:33.141363Z","shell.execute_reply.started":"2024-11-05T01:40:33.130195Z","shell.execute_reply":"2024-11-05T01:40:33.140248Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"Index(['userName', 'verified', 'itemName', 'description', 'image', 'brand',\n       'feature', 'category', 'price', 'rating', 'reviewTime', 'summary',\n       'reviewText', 'vote'],\n      dtype='object')"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"# removing columns: verivied, image, feature\ninter_cols =  ['userName', 'itemName', 'description', 'brand', 'category', 'price', 'rating', 'reviewTime', 'summary',\n       'reviewText', 'vote']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.143194Z","iopub.execute_input":"2024-11-05T01:40:33.143639Z","iopub.status.idle":"2024-11-05T01:40:33.151803Z","shell.execute_reply.started":"2024-11-05T01:40:33.143581Z","shell.execute_reply":"2024-11-05T01:40:33.150632Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"df_2 = df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.153233Z","iopub.execute_input":"2024-11-05T01:40:33.153575Z","iopub.status.idle":"2024-11-05T01:40:33.250891Z","shell.execute_reply.started":"2024-11-05T01:40:33.153540Z","shell.execute_reply":"2024-11-05T01:40:33.249684Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"df_2 = df_2.drop(['verified', 'image', 'feature'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.254627Z","iopub.execute_input":"2024-11-05T01:40:33.255029Z","iopub.status.idle":"2024-11-05T01:40:33.380637Z","shell.execute_reply.started":"2024-11-05T01:40:33.254991Z","shell.execute_reply":"2024-11-05T01:40:33.379559Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"df_2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.381931Z","iopub.execute_input":"2024-11-05T01:40:33.382297Z","iopub.status.idle":"2024-11-05T01:40:33.399806Z","shell.execute_reply.started":"2024-11-05T01:40:33.382260Z","shell.execute_reply":"2024-11-05T01:40:33.398657Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"          userName                                           itemName  \\\n0  Amazon Customer  Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...   \n1            Carla  Prince of Peace Organic Tea, Oolong, 100 Tea Bags   \n2           Jaclyn  Pet Champion Adjustable No-Pull Harness, Colla...   \n3     Christinne M  Koh-I-Noor Progresso Woodless Colored 24-Penci...   \n4            Sandy  Parker Urban Premium Ebony Metal Chiseled, Bal...   \n\n                                         description            brand  \\\n0  [\"Made from deliciously decadent ingredients, ...        Toblerone   \n1  ['Prince of Peace Enterprises, Inc., founded i...  Prince Of Peace   \n2  [\"The Pet Champion Large/ Extra Large 22-36 in...     Pet Champion   \n3  ['Koh-I-Noor Progresso Woodless Colored 24-Pen...       KOH-I-NOOR   \n4  [\"Stunning craftsmanship based on a classic st...           Parker   \n\n                   category   price  rating  reviewTime  \\\n0              Prime_Pantry   $1.63     5.0  2018-01-01   \n1  Grocery_and_Gourmet_Food   $6.40     5.0  2018-01-01   \n2              Pet_Supplies   $7.99     5.0  2018-01-01   \n3    Arts_Crafts_and_Sewing  $14.18     5.0  2018-01-01   \n4           Office_Products     NaN     5.0  2018-01-01   \n\n                                             summary  \\\n0                                         Five Stars   \n1                                         Five Stars   \n2  she has an odd shape chest and her pull over h...   \n3                                           Loving!!   \n4                                    I love this pen   \n\n                                          reviewText  vote  \n0           super smooth and yummy with crunchy bits     0  \n1                               Perfect for kombucha     0  \n2  Finally a harness that fits my puppy. I really...     0  \n3  I LOVE THEM!! I bought them at Micheals our of...     0  \n4  I love this pen! I love the shape of it, the f...     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userName</th>\n      <th>itemName</th>\n      <th>description</th>\n      <th>brand</th>\n      <th>category</th>\n      <th>price</th>\n      <th>rating</th>\n      <th>reviewTime</th>\n      <th>summary</th>\n      <th>reviewText</th>\n      <th>vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amazon Customer</td>\n      <td>Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...</td>\n      <td>[\"Made from deliciously decadent ingredients, ...</td>\n      <td>Toblerone</td>\n      <td>Prime_Pantry</td>\n      <td>$1.63</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>super smooth and yummy with crunchy bits</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carla</td>\n      <td>Prince of Peace Organic Tea, Oolong, 100 Tea Bags</td>\n      <td>['Prince of Peace Enterprises, Inc., founded i...</td>\n      <td>Prince Of Peace</td>\n      <td>Grocery_and_Gourmet_Food</td>\n      <td>$6.40</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>Perfect for kombucha</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jaclyn</td>\n      <td>Pet Champion Adjustable No-Pull Harness, Colla...</td>\n      <td>[\"The Pet Champion Large/ Extra Large 22-36 in...</td>\n      <td>Pet Champion</td>\n      <td>Pet_Supplies</td>\n      <td>$7.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>she has an odd shape chest and her pull over h...</td>\n      <td>Finally a harness that fits my puppy. I really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christinne M</td>\n      <td>Koh-I-Noor Progresso Woodless Colored 24-Penci...</td>\n      <td>['Koh-I-Noor Progresso Woodless Colored 24-Pen...</td>\n      <td>KOH-I-NOOR</td>\n      <td>Arts_Crafts_and_Sewing</td>\n      <td>$14.18</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Loving!!</td>\n      <td>I LOVE THEM!! I bought them at Micheals our of...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sandy</td>\n      <td>Parker Urban Premium Ebony Metal Chiseled, Bal...</td>\n      <td>[\"Stunning craftsmanship based on a classic st...</td>\n      <td>Parker</td>\n      <td>Office_Products</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>I love this pen</td>\n      <td>I love this pen! I love the shape of it, the f...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"def input_str(abc):\n    if ('$'  not  in str(abc)):\n       return  -1\n    elif('-' in str(abc)):\n        z = str(abc).replace('$','').replace(',','').replace(' ','').split('-')\n        return  float((float(z[0]) + float(z[1]) )/2 )\n    else:\n        return  float(str(abc).replace('$','').replace(' ','').replace(',',''))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.401487Z","iopub.execute_input":"2024-11-05T01:40:33.401982Z","iopub.status.idle":"2024-11-05T01:40:33.410015Z","shell.execute_reply.started":"2024-11-05T01:40:33.401934Z","shell.execute_reply":"2024-11-05T01:40:33.408706Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"df_2['price'] = df_2['price'].apply(input_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.411593Z","iopub.execute_input":"2024-11-05T01:40:33.412186Z","iopub.status.idle":"2024-11-05T01:40:33.879730Z","shell.execute_reply.started":"2024-11-05T01:40:33.412137Z","shell.execute_reply":"2024-11-05T01:40:33.878628Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"new_latest_set  =  df_2[ df_2['price'] > -1   ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.881009Z","iopub.execute_input":"2024-11-05T01:40:33.881345Z","iopub.status.idle":"2024-11-05T01:40:33.984850Z","shell.execute_reply.started":"2024-11-05T01:40:33.881310Z","shell.execute_reply":"2024-11-05T01:40:33.983728Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"df_2 = new_latest_set.drop_duplicates()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:33.986224Z","iopub.execute_input":"2024-11-05T01:40:33.986587Z","iopub.status.idle":"2024-11-05T01:40:35.158284Z","shell.execute_reply.started":"2024-11-05T01:40:33.986550Z","shell.execute_reply":"2024-11-05T01:40:35.157185Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"df_2.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.159682Z","iopub.execute_input":"2024-11-05T01:40:35.160061Z","iopub.status.idle":"2024-11-05T01:40:35.167252Z","shell.execute_reply.started":"2024-11-05T01:40:35.160025Z","shell.execute_reply":"2024-11-05T01:40:35.165779Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"(428529, 11)"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"df_2['category'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.168948Z","iopub.execute_input":"2024-11-05T01:40:35.169568Z","iopub.status.idle":"2024-11-05T01:40:35.215868Z","shell.execute_reply.started":"2024-11-05T01:40:35.169526Z","shell.execute_reply":"2024-11-05T01:40:35.214637Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"category\nPet_Supplies                   148297\nGrocery_and_Gourmet_Food        73867\nPatio_Lawn_and_Garden           55422\nOffice_Products                 48383\nCell_Phones_and_Accessories     33241\nArts_Crafts_and_Sewing          31101\nPrime_Pantry                    14408\nMusical_Instruments             13686\nIndustrial_and_Scientific        5271\nVideo_Games                      2762\nLuxury_Beauty                    1679\nAMAZON_FASHION                    217\nSoftware                           82\nAll_Beauty                         75\nDigital_Music                      33\nAppliances                          5\nName: count, dtype: int64"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"df_3 = df_2.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.217432Z","iopub.execute_input":"2024-11-05T01:40:35.217922Z","iopub.status.idle":"2024-11-05T01:40:35.409490Z","shell.execute_reply.started":"2024-11-05T01:40:35.217846Z","shell.execute_reply":"2024-11-05T01:40:35.408344Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"df_3.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.410731Z","iopub.execute_input":"2024-11-05T01:40:35.411089Z","iopub.status.idle":"2024-11-05T01:40:35.418322Z","shell.execute_reply.started":"2024-11-05T01:40:35.411052Z","shell.execute_reply":"2024-11-05T01:40:35.417162Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"(428529, 11)"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"df_3.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.419669Z","iopub.execute_input":"2024-11-05T01:40:35.420027Z","iopub.status.idle":"2024-11-05T01:40:35.440422Z","shell.execute_reply.started":"2024-11-05T01:40:35.419992Z","shell.execute_reply":"2024-11-05T01:40:35.438980Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"          userName                                           itemName  \\\n0  Amazon Customer  Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...   \n1            Carla  Prince of Peace Organic Tea, Oolong, 100 Tea Bags   \n2           Jaclyn  Pet Champion Adjustable No-Pull Harness, Colla...   \n3     Christinne M  Koh-I-Noor Progresso Woodless Colored 24-Penci...   \n6          patrick  Blue Buffalo Life Protection Formula Natural P...   \n\n                                         description            brand  \\\n0  [\"Made from deliciously decadent ingredients, ...        Toblerone   \n1  ['Prince of Peace Enterprises, Inc., founded i...  Prince Of Peace   \n2  [\"The Pet Champion Large/ Extra Large 22-36 in...     Pet Champion   \n3  ['Koh-I-Noor Progresso Woodless Colored 24-Pen...       KOH-I-NOOR   \n6  ['Because puppyhood is such an important stage...     Blue Buffalo   \n\n                   category  price  rating  reviewTime  \\\n0              Prime_Pantry   1.63     5.0  2018-01-01   \n1  Grocery_and_Gourmet_Food   6.40     5.0  2018-01-01   \n2              Pet_Supplies   7.99     5.0  2018-01-01   \n3    Arts_Crafts_and_Sewing  14.18     5.0  2018-01-01   \n6              Pet_Supplies  28.99     5.0  2018-01-01   \n\n                                             summary  \\\n0                                         Five Stars   \n1                                         Five Stars   \n2  she has an odd shape chest and her pull over h...   \n3                                           Loving!!   \n6  ... and has had no problems with this food - B...   \n\n                                          reviewText  vote  \n0           super smooth and yummy with crunchy bits     0  \n1                               Perfect for kombucha     0  \n2  Finally a harness that fits my puppy. I really...     0  \n3  I LOVE THEM!! I bought them at Micheals our of...     0  \n6  My 1 year old husky loves it - healthy and has...     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userName</th>\n      <th>itemName</th>\n      <th>description</th>\n      <th>brand</th>\n      <th>category</th>\n      <th>price</th>\n      <th>rating</th>\n      <th>reviewTime</th>\n      <th>summary</th>\n      <th>reviewText</th>\n      <th>vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amazon Customer</td>\n      <td>Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...</td>\n      <td>[\"Made from deliciously decadent ingredients, ...</td>\n      <td>Toblerone</td>\n      <td>Prime_Pantry</td>\n      <td>1.63</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>super smooth and yummy with crunchy bits</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carla</td>\n      <td>Prince of Peace Organic Tea, Oolong, 100 Tea Bags</td>\n      <td>['Prince of Peace Enterprises, Inc., founded i...</td>\n      <td>Prince Of Peace</td>\n      <td>Grocery_and_Gourmet_Food</td>\n      <td>6.40</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>Perfect for kombucha</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jaclyn</td>\n      <td>Pet Champion Adjustable No-Pull Harness, Colla...</td>\n      <td>[\"The Pet Champion Large/ Extra Large 22-36 in...</td>\n      <td>Pet Champion</td>\n      <td>Pet_Supplies</td>\n      <td>7.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>she has an odd shape chest and her pull over h...</td>\n      <td>Finally a harness that fits my puppy. I really...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christinne M</td>\n      <td>Koh-I-Noor Progresso Woodless Colored 24-Penci...</td>\n      <td>['Koh-I-Noor Progresso Woodless Colored 24-Pen...</td>\n      <td>KOH-I-NOOR</td>\n      <td>Arts_Crafts_and_Sewing</td>\n      <td>14.18</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Loving!!</td>\n      <td>I LOVE THEM!! I bought them at Micheals our of...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>patrick</td>\n      <td>Blue Buffalo Life Protection Formula Natural P...</td>\n      <td>['Because puppyhood is such an important stage...</td>\n      <td>Blue Buffalo</td>\n      <td>Pet_Supplies</td>\n      <td>28.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>... and has had no problems with this food - B...</td>\n      <td>My 1 year old husky loves it - healthy and has...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"# df_3.to_excel('Final_Reduced_Amazon_Review.xlsx') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.442397Z","iopub.execute_input":"2024-11-05T01:40:35.442927Z","iopub.status.idle":"2024-11-05T01:40:35.451229Z","shell.execute_reply.started":"2024-11-05T01:40:35.442878Z","shell.execute_reply":"2024-11-05T01:40:35.448959Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"df_3[df_3['category'] == 'Pet_Supplies']['reviewText'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.453418Z","iopub.execute_input":"2024-11-05T01:40:35.453940Z","iopub.status.idle":"2024-11-05T01:40:35.679353Z","shell.execute_reply.started":"2024-11-05T01:40:35.453886Z","shell.execute_reply":"2024-11-05T01:40:35.678201Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"reviewText\ngreat                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             225\ngood                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              218\nok                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                188\nGreat                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             188\nGood                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              158\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ... \nIve had trouble finding a brush that works on my chihuahua. He has coarse, short hair and sheds A LOT. The Furminator (which Ive used very successfully with other animals) doesnt grab *any* of his fur. I have now tried multiple other brushes and this is the only one that removes any of his loose hairs. He really likes being brushed with this and gets kinda winy when I put the brush away. Only downside is his hair doesnt really stick to the blade - I find I need to brush him on a towel that can catch the hair because it just falls off in all directions.      1\nPrincess likes it but she prefers the fish ones more                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\nSome were too small but not bad for price                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\nI LOVE THIS SHAMPOO FOR MY DOGS SENSITIVE SKIN AND SMELLS SO GOOD.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\nMy cats love it.  I just wish it wasn't so expensive.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\nName: count, Length: 132929, dtype: int64"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"# Ensure stopwords are loaded\nstop_words = list(stopwords.words(\"english\"))\n\ndef top_words_by_sentiment(df, category, n=5):\n    \"\"\"\n    Extract the top positive and negative words for a specific category in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - category (str): The category to filter by.\n    - n (int): The number of top words to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Top positive and negative words for the specified category.\n    \"\"\"\n    \n    # Filter for the specified category\n    category_df = df[df['category'] == category]\n    \n    # Separate positive and negative reviews based on 'vote' values\n    positive_reviews = category_df[category_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = category_df[category_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words\n    vectorizer = CountVectorizer(stop_words=stop_words)\n    \n    # Positive words frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_words = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_words = sorted(positive_words.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative words frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_words = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_words = sorted(negative_words.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    return {\n        'top_positive_words': top_positive_words,\n        'top_negative_words': top_negative_words\n    }\n\n# Example Usage: Top words in the 'Pet_Supplies' category\ntop_words_pet_supplies = top_words_by_sentiment(df_3, category=\"Pet_Supplies\", n=5)\nprint(top_words_pet_supplies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:35.680444Z","iopub.execute_input":"2024-11-05T01:40:35.680829Z","iopub.status.idle":"2024-11-05T01:40:40.057177Z","shell.execute_reply.started":"2024-11-05T01:40:35.680784Z","shell.execute_reply":"2024-11-05T01:40:40.056032Z"}},"outputs":[{"name":"stdout","text":"{'top_positive_words': [('dog', 32629), ('great', 26304), ('love', 24226), ('one', 20748), ('dogs', 18084)], 'top_negative_words': [('dog', 6269), ('one', 3872), ('like', 3586), ('would', 3318), ('dogs', 2689)]}\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# Download required NLTK data\nnltk.download(\"stopwords\")\nnltk.download(\"averaged_perceptron_tagger\")\nnltk.download(\"punkt\")\n\n# Define general stop words\ngeneral_stop_words = set(stopwords.words(\"english\"))\n\ndef filter_sentiment_adjectives(text):\n    \"\"\"Filter adjectives that convey sentiment from text.\"\"\"\n    words = word_tokenize(text)\n    filtered_words = [word for word, pos in pos_tag(words) if pos.startswith('JJ')]  # JJ for adjectives\n    return ' '.join(filtered_words)\n\ndef top_words_by_sentiment(df, category, custom_stop_words=None, n=5):\n    \"\"\"\n    Extract the top positive and negative sentiment adjectives for a specific category in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - category (str): The category to filter by.\n    - custom_stop_words (set): A set of additional stop words specific to the category.\n    - n (int): The number of top words to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Top positive and negative sentiment adjectives for the specified category.\n    \"\"\"\n    \n    # Combine general and custom stop words\n    stop_words = general_stop_words.union(custom_stop_words or set())\n    \n    # Filter for the specified category\n    category_df = df[df['category'] == category]\n    \n    # Separate positive and negative reviews and filter for sentiment adjectives\n    positive_reviews = category_df[category_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\").apply(filter_sentiment_adjectives)\n    negative_reviews = category_df[category_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\").apply(filter_sentiment_adjectives)\n    \n    # Vectorize with TF-IDF and category-specific stop words\n    vectorizer = TfidfVectorizer(stop_words=list(stop_words), max_df=0.85, min_df=2)\n    \n    # Positive sentiment words\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_words = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_words = sorted(positive_words.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative sentiment words\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_words = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_words = sorted(negative_words.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    return {\n        'top_positive_words': top_positive_words,\n        'top_negative_words': top_negative_words\n    }\n\n# Example usage for a category-specific stop word list\npet_stop_words = {\"dog\", \"dogs\", \"cat\", \"cats\", \"food\", \"treat\"}  # Example for pet-related products\ntop_words_pet_supplies = top_words_by_sentiment(df_3, category=\"Pet_Supplies\", custom_stop_words=pet_stop_words, n=5)\nprint(top_words_pet_supplies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:40:40.058646Z","iopub.execute_input":"2024-11-05T01:40:40.059037Z","iopub.status.idle":"2024-11-05T01:47:25.669258Z","shell.execute_reply.started":"2024-11-05T01:40:40.059000Z","shell.execute_reply":"2024-11-05T01:47:25.668150Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n[nltk_data]     [Errno -3] Temporary failure in name resolution>\n[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n{'top_positive_words': [('great', 8253.660612779175), ('good', 7058.677603197927), ('little', 3118.878655684278), ('easy', 2770.9115359051966), ('small', 2533.0291411789794)], 'top_negative_words': [('small', 764.9020565894398), ('good', 558.7144531856251), ('great', 337.5743304056612), ('first', 333.89991227127194), ('last', 326.41300810730183)]}\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"top_words_pet_supplies = top_words_by_sentiment(df_3, category=\"Grocery_and_Gourmet_Food\", n=5)\nprint(top_words_pet_supplies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:47:25.670940Z","iopub.execute_input":"2024-11-05T01:47:25.671909Z","iopub.status.idle":"2024-11-05T01:49:41.735509Z","shell.execute_reply.started":"2024-11-05T01:47:25.671852Z","shell.execute_reply":"2024-11-05T01:49:41.733703Z"}},"outputs":[{"name":"stdout","text":"{'top_positive_words': [('good', 7588.934658933644), ('great', 5171.929509889076), ('delicious', 2008.6091655102337), ('best', 1852.1313248432457), ('favorite', 1233.7901959783997)], 'top_negative_words': [('good', 370.45066798397363), ('much', 177.76805825518886), ('bad', 177.05061828724578), ('sweet', 143.56913338174968), ('disappointed', 140.50729616204572)]}\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"# Ensure stopwords are loaded and convert custom stop words to a list\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))  # Add custom stop words here\n\ndef top_bigrams_by_sentiment(df, category, n=5):\n    \"\"\"\n    Extract the top positive and negative bigrams for a specific category in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - category (str): The category to filter by.\n    - n (int): The number of top bigrams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Top positive and negative bigrams for the specified category.\n    \"\"\"\n    \n    # Filter for the specified category\n    category_df = df[df['category'] == category]\n    \n    # Separate positive and negative reviews based on 'vote' values\n    positive_reviews = category_df[category_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = category_df[category_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and bigrams (2-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2, 2), max_df=0.85)\n    \n    # Positive bigrams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_bigrams = sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative bigrams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_bigrams = sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    return {\n        'top_positive_bigrams': top_positive_bigrams,\n        'top_negative_bigrams': top_negative_bigrams\n    }\n\n# Example Usage: Top 5 bigrams in the 'Pet_Supplies' category\ntop_bigrams_pet_supplies = top_bigrams_by_sentiment(df_3, category=\"Pet_Supplies\", n=10)\nprint(top_bigrams_pet_supplies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:49:41.737118Z","iopub.execute_input":"2024-11-05T01:49:41.737510Z","iopub.status.idle":"2024-11-05T01:49:56.247569Z","shell.execute_reply.started":"2024-11-05T01:49:41.737467Z","shell.execute_reply":"2024-11-05T01:49:56.246379Z"}},"outputs":[{"name":"stdout","text":"{'top_positive_bigrams': [('dog loves', 1407.951338343776), ('dogs love', 1364.003153762774), ('cats love', 901.7169554828833), ('works great', 898.4260866067975), ('cat loves', 565.3566776417244), ('works well', 500.3906644937572), ('great price', 457.61542266446264), ('well made', 377.1061673684012), ('good quality', 361.18842299045906), ('good price', 300.4400018679215)], 'top_negative_bigrams': [('waste money', 96.17973205671959), ('dog like', 51.82463463744514), ('cats like', 47.313439353715495), ('dogs like', 43.06482715089331), ('way small', 38.1876348254157), ('cheaply made', 35.999750915832585), ('would eat', 34.711533148106085), ('dog eat', 34.18741552000601), ('work well', 32.25488409504563), ('small dog', 32.17754938953153)]}\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Download stopwords\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Preprocessing function\ndef preprocess_text(text):\n    # Remove special characters\n    text = re.sub(r'\\W', ' ', str(text))\n    # Lowercase\n    text = text.lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    return text\n\n# Applying preprocessing on the reviewText column\ndf_3['processed_reviewText'] = df_3['reviewText'].fillna('').apply(preprocess_text)\n\n# Assign labels based on 'vote'\ndef assign_sentiment_label(rating):\n    if rating in [4, 5]:\n        return 'positive'\n    elif rating in [1, 2]:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Add sentiment labels\ndf_3['sentiment'] = df_3['rating'].apply(assign_sentiment_label)\n\n# Split data for training and testing\nX_train, X_test, y_train, y_test = train_test_split(\n    df_3['processed_reviewText'], df_3['sentiment'], test_size=0.25, random_state=42\n)\n\n# Define model pipeline\nmodel = make_pipeline(CountVectorizer(), MultinomialNB())\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred = model.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Function to predict sentiment or appropriateness of new reviews\ndef check_review_sentiment(review):\n    processed_review = preprocess_text(review)\n    prediction = model.predict([processed_review])[0]\n    return prediction\n\n# Example usage\nnew_review = \"This product is a scam and does not work!\"\nprint(\"Review:\", new_review)\nprint(\"Predicted Sentiment:\", check_review_sentiment(new_review))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:49:56.249052Z","iopub.execute_input":"2024-11-05T01:49:56.249414Z","iopub.status.idle":"2024-11-05T01:50:36.349341Z","shell.execute_reply.started":"2024-11-05T01:49:56.249376Z","shell.execute_reply":"2024-11-05T01:50:36.348170Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nAccuracy: 0.8547693054427674\nClassification Report:\n               precision    recall  f1-score   support\n\n    negative       0.65      0.47      0.55     11033\n     neutral       0.36      0.10      0.15      7964\n    positive       0.88      0.97      0.92     88136\n\n    accuracy                           0.85    107133\n   macro avg       0.63      0.51      0.54    107133\nweighted avg       0.82      0.85      0.83    107133\n\nReview: This product is a scam and does not work!\nPredicted Sentiment: negative\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"df_4 = df_2.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:36.356866Z","iopub.execute_input":"2024-11-05T01:50:36.357241Z","iopub.status.idle":"2024-11-05T01:50:36.537275Z","shell.execute_reply.started":"2024-11-05T01:50:36.357207Z","shell.execute_reply":"2024-11-05T01:50:36.535635Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"df_4.shape # and head() to sanity check","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:36.538987Z","iopub.execute_input":"2024-11-05T01:50:36.539499Z","iopub.status.idle":"2024-11-05T01:50:36.549061Z","shell.execute_reply.started":"2024-11-05T01:50:36.539441Z","shell.execute_reply":"2024-11-05T01:50:36.547638Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"(428529, 11)"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"# Calculate the total amount spent by each user\nuser_total_spent = df_4.groupby('userName')['price'].sum()\nuser_total_spent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:36.550350Z","iopub.execute_input":"2024-11-05T01:50:36.550676Z","iopub.status.idle":"2024-11-05T01:50:36.879592Z","shell.execute_reply.started":"2024-11-05T01:50:36.550643Z","shell.execute_reply":"2024-11-05T01:50:36.878494Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"userName\n                      10.99\n #345876236754444     33.03\n (Kuro)                9.99\n Becca                57.84\n Berta Mae            10.34\n                      ...  \n~heavv~               33.97\n~michelle~           172.35\n~purplemoon~         138.86\n~~Joe~~                2.86\n~~Trish~~            189.69\nName: price, Length: 121208, dtype: float64"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"# Fill NaN values in 'userName' with a placeholder to avoid KeyError (bellow)\ndf_4['userName'] = df_4['userName'].fillna(\"Unknown\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:36.881002Z","iopub.execute_input":"2024-11-05T01:50:36.882102Z","iopub.status.idle":"2024-11-05T01:50:36.930846Z","shell.execute_reply.started":"2024-11-05T01:50:36.882043Z","shell.execute_reply":"2024-11-05T01:50:36.929678Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"unknown_user_count = df_4['userName'].value_counts().get('Unknown', 0)\nprint(f\"Number of 'Unknown' user names: {unknown_user_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:36.932288Z","iopub.execute_input":"2024-11-05T01:50:36.932653Z","iopub.status.idle":"2024-11-05T01:50:37.123123Z","shell.execute_reply.started":"2024-11-05T01:50:36.932616Z","shell.execute_reply":"2024-11-05T01:50:37.121848Z"}},"outputs":[{"name":"stdout","text":"Number of 'Unknown' user names: 121\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"df_4['userName'].value_counts().head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:37.124524Z","iopub.execute_input":"2024-11-05T01:50:37.125055Z","iopub.status.idle":"2024-11-05T01:50:37.295002Z","shell.execute_reply.started":"2024-11-05T01:50:37.124989Z","shell.execute_reply":"2024-11-05T01:50:37.293895Z"}},"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"userName\nAmazon Customer    27196\nKindle Customer     2081\nMike                 504\nName: count, dtype: int64"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"# Adding a new column 'Amazon_verified' indicating if a user has spent more than $50\ndf_4['Amazon_verified'] = df_4['userName'].map(lambda user: 'Verified' if user_total_spent[user] >= 50 else 'Not Verified')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:37.296533Z","iopub.execute_input":"2024-11-05T01:50:37.297004Z","iopub.status.idle":"2024-11-05T01:50:38.920995Z","shell.execute_reply.started":"2024-11-05T01:50:37.296955Z","shell.execute_reply":"2024-11-05T01:50:38.919823Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"# Filter for specific usernames and get the value counts for 'Amazon_verified'\namazon_customer_verified_counts = df_4[df_4['userName'] == \"Amazon Customer\"]['Amazon_verified'].value_counts()\nkindle_customer_verified_counts = df_4[df_4['userName'] == \"Kindle Customer\"]['Amazon_verified'].value_counts()\n\nprint(\"Amazon Customer Verification Status Counts:\\n\", amazon_customer_verified_counts)\nprint(\"\\nKindle Customer Verification Status Counts:\\n\", kindle_customer_verified_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:38.922228Z","iopub.execute_input":"2024-11-05T01:50:38.922553Z","iopub.status.idle":"2024-11-05T01:50:39.028041Z","shell.execute_reply.started":"2024-11-05T01:50:38.922520Z","shell.execute_reply":"2024-11-05T01:50:39.026817Z"}},"outputs":[{"name":"stdout","text":"Amazon Customer Verification Status Counts:\n Amazon_verified\nVerified    27196\nName: count, dtype: int64\n\nKindle Customer Verification Status Counts:\n Amazon_verified\nVerified    2081\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"df_4.shape # perfect - new column added","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:39.029474Z","iopub.execute_input":"2024-11-05T01:50:39.029893Z","iopub.status.idle":"2024-11-05T01:50:39.037208Z","shell.execute_reply.started":"2024-11-05T01:50:39.029854Z","shell.execute_reply":"2024-11-05T01:50:39.035958Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"(428529, 12)"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"df_4['Amazon_verified'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:39.038673Z","iopub.execute_input":"2024-11-05T01:50:39.039103Z","iopub.status.idle":"2024-11-05T01:50:39.073396Z","shell.execute_reply.started":"2024-11-05T01:50:39.039065Z","shell.execute_reply":"2024-11-05T01:50:39.072139Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"Amazon_verified\nVerified        301613\nNot Verified    126916\nName: count, dtype: int64"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"# suggesting a new condition to leverage the comments:\n# Calculate total transactions per user\nuser_transaction_counts = df_4['userName'].value_counts()\n\n# Adding a new column 'Amazon_verified_levarage' with updated verification logic\ndf_4['Amazon_verified_leverage'] = df_4['userName'].map(\n    lambda user: 'Verified' if (user_total_spent.get(user, 0) >= 30 or user_transaction_counts.get(user, 0) >= 3) else 'Not Verified'\n)\n\n# Display the counts of each status in the new column\nprint(df_4['Amazon_verified_leverage'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:39.074921Z","iopub.execute_input":"2024-11-05T01:50:39.075381Z","iopub.status.idle":"2024-11-05T01:50:41.347664Z","shell.execute_reply.started":"2024-11-05T01:50:39.075336Z","shell.execute_reply":"2024-11-05T01:50:41.346375Z"}},"outputs":[{"name":"stdout","text":"Amazon_verified_leverage\nVerified        362280\nNot Verified     66249\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"df_4.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:41.349031Z","iopub.execute_input":"2024-11-05T01:50:41.349508Z","iopub.status.idle":"2024-11-05T01:50:41.368015Z","shell.execute_reply.started":"2024-11-05T01:50:41.349461Z","shell.execute_reply":"2024-11-05T01:50:41.366456Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"          userName                                           itemName  \\\n0  Amazon Customer  Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...   \n1            Carla  Prince of Peace Organic Tea, Oolong, 100 Tea Bags   \n2           Jaclyn  Pet Champion Adjustable No-Pull Harness, Colla...   \n3     Christinne M  Koh-I-Noor Progresso Woodless Colored 24-Penci...   \n6          patrick  Blue Buffalo Life Protection Formula Natural P...   \n\n                                         description            brand  \\\n0  [\"Made from deliciously decadent ingredients, ...        Toblerone   \n1  ['Prince of Peace Enterprises, Inc., founded i...  Prince Of Peace   \n2  [\"The Pet Champion Large/ Extra Large 22-36 in...     Pet Champion   \n3  ['Koh-I-Noor Progresso Woodless Colored 24-Pen...       KOH-I-NOOR   \n6  ['Because puppyhood is such an important stage...     Blue Buffalo   \n\n                   category  price  rating  reviewTime  \\\n0              Prime_Pantry   1.63     5.0  2018-01-01   \n1  Grocery_and_Gourmet_Food   6.40     5.0  2018-01-01   \n2              Pet_Supplies   7.99     5.0  2018-01-01   \n3    Arts_Crafts_and_Sewing  14.18     5.0  2018-01-01   \n6              Pet_Supplies  28.99     5.0  2018-01-01   \n\n                                             summary  \\\n0                                         Five Stars   \n1                                         Five Stars   \n2  she has an odd shape chest and her pull over h...   \n3                                           Loving!!   \n6  ... and has had no problems with this food - B...   \n\n                                          reviewText  vote Amazon_verified  \\\n0           super smooth and yummy with crunchy bits     0        Verified   \n1                               Perfect for kombucha     0        Verified   \n2  Finally a harness that fits my puppy. I really...     0        Verified   \n3  I LOVE THEM!! I bought them at Micheals our of...     0    Not Verified   \n6  My 1 year old husky loves it - healthy and has...     0        Verified   \n\n  Amazon_verified_leverage  \n0                 Verified  \n1                 Verified  \n2                 Verified  \n3             Not Verified  \n6                 Verified  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userName</th>\n      <th>itemName</th>\n      <th>description</th>\n      <th>brand</th>\n      <th>category</th>\n      <th>price</th>\n      <th>rating</th>\n      <th>reviewTime</th>\n      <th>summary</th>\n      <th>reviewText</th>\n      <th>vote</th>\n      <th>Amazon_verified</th>\n      <th>Amazon_verified_leverage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amazon Customer</td>\n      <td>Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...</td>\n      <td>[\"Made from deliciously decadent ingredients, ...</td>\n      <td>Toblerone</td>\n      <td>Prime_Pantry</td>\n      <td>1.63</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>super smooth and yummy with crunchy bits</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carla</td>\n      <td>Prince of Peace Organic Tea, Oolong, 100 Tea Bags</td>\n      <td>['Prince of Peace Enterprises, Inc., founded i...</td>\n      <td>Prince Of Peace</td>\n      <td>Grocery_and_Gourmet_Food</td>\n      <td>6.40</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>Perfect for kombucha</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jaclyn</td>\n      <td>Pet Champion Adjustable No-Pull Harness, Colla...</td>\n      <td>[\"The Pet Champion Large/ Extra Large 22-36 in...</td>\n      <td>Pet Champion</td>\n      <td>Pet_Supplies</td>\n      <td>7.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>she has an odd shape chest and her pull over h...</td>\n      <td>Finally a harness that fits my puppy. I really...</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christinne M</td>\n      <td>Koh-I-Noor Progresso Woodless Colored 24-Penci...</td>\n      <td>['Koh-I-Noor Progresso Woodless Colored 24-Pen...</td>\n      <td>KOH-I-NOOR</td>\n      <td>Arts_Crafts_and_Sewing</td>\n      <td>14.18</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Loving!!</td>\n      <td>I LOVE THEM!! I bought them at Micheals our of...</td>\n      <td>0</td>\n      <td>Not Verified</td>\n      <td>Not Verified</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>patrick</td>\n      <td>Blue Buffalo Life Protection Formula Natural P...</td>\n      <td>['Because puppyhood is such an important stage...</td>\n      <td>Blue Buffalo</td>\n      <td>Pet_Supplies</td>\n      <td>28.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>... and has had no problems with this food - B...</td>\n      <td>My 1 year old husky loves it - healthy and has...</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"# Calculating the total sales for each product\nproduct_sales = df_4.groupby('itemName')['price'].sum().sort_values(ascending=False)\nproduct_sales","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:41.370421Z","iopub.execute_input":"2024-11-05T01:50:41.370928Z","iopub.status.idle":"2024-11-05T01:50:41.700015Z","shell.execute_reply.started":"2024-11-05T01:50:41.370885Z","shell.execute_reply":"2024-11-05T01:50:41.698952Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"itemName\nMidWest Homes for Pets Dog Crate | iCrate Single Door &amp; Double Door Folding Metal Dog Crates    22788.92\nNIKE Women's Flex Supreme TR 4 Cross Trainer                                                        17498.00\nCanon EOS Rebel T5 18MP EF-S Digital SLR Camera Bundle with Tripod and Accessories (16 Items)       16798.60\nPurina Fortiflora Nutritional Supplement for Cats                                                   15114.60\nPuppia Dog Harnesses                                                                                14830.66\n                                                                                                      ...   \nApache OpenOffice 4.0.1 [Open Source Download]                                                          0.00\nAmazon Music [Mac] [Download]                                                                           0.00\nKindle for PC [Download]                                                                                0.00\nAdobe Flash Player 16 for Windows [Download]                                                            0.00\nSony ACID Music Studio 10- 30 Day Free Trial [Download]                                                 0.00\nName: price, Length: 85163, dtype: float64"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"# Filter out rows where 'reviewText' is missing or empty, then count each itemName\nreviewed_product_counts = df_4[df_4['reviewText'].notna() & (df_4['reviewText'].str.strip() != '')]['itemName'].value_counts()\nreviewed_product_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:41.701406Z","iopub.execute_input":"2024-11-05T01:50:41.701766Z","iopub.status.idle":"2024-11-05T01:50:42.257034Z","shell.execute_reply.started":"2024-11-05T01:50:41.701705Z","shell.execute_reply":"2024-11-05T01:50:42.255958Z"}},"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"itemName\nPuppia Dog Harnesses                                                                                                             988\nKIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count                                             737\nKIND Bars, Caramel Almond and Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count                                                    702\nKind Bars, Madagascar Vanilla Almond, Gluten Free, Low Sugar, 1.4oz                                                              664\nKIND Bars, Dark Chocolate Chili Almond, Gluten Free, 1.4 Ounce Bars, 12 Count                                                    658\n                                                                                                                                ... \nSafari Stainless Steel Double-Bladed Nail Trimmer for Cats, Kittens and Small Animals                                              1\nPringles 3 Flavor Snack Stacks, 12.69 Ounce (Pack of 4)                                                                            1\nGeneric Waterproof Shockproof Dirt Proof Snow Proof Protection Case Cover for Apple iPhone 4/4s - Non-Retail Packaging - Blue      1\nOval No Soliciting Sign (Ivory) - Small                                                                                            1\nPDP Titanfall 2 Official Marauder SRS Stereo Headset for PlayStation 4                                                             1\nName: count, Length: 85141, dtype: int64"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"# Calculating the total number of transactions for each product\nproduct_transactions = df_4['itemName'].value_counts().sort_values(ascending=False)\nproduct_transactions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:42.258430Z","iopub.execute_input":"2024-11-05T01:50:42.259009Z","iopub.status.idle":"2024-11-05T01:50:42.502006Z","shell.execute_reply.started":"2024-11-05T01:50:42.258965Z","shell.execute_reply":"2024-11-05T01:50:42.500533Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"itemName\nPuppia Dog Harnesses                                                                                                                                                                               988\nKIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count                                                                                                               737\nKIND Bars, Caramel Almond and Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count                                                                                                                      702\nKind Bars, Madagascar Vanilla Almond, Gluten Free, Low Sugar, 1.4oz                                                                                                                                664\nKIND Bars, Dark Chocolate Chili Almond, Gluten Free, 1.4 Ounce Bars, 12 Count                                                                                                                      658\n                                                                                                                                                                                                  ... \nSUVAPOTAC iPhone 6S/6 Plus Screen Protector, [3-Pack ] [Tempered Glass] HD Clear,Ultra Thin Case Friendly,Easy Application,Bubble Free,Anti-Scratch Glass Screen Protector for iPhone 6S/6 Plus      1\nRotary 6125 Blade                                                                                                                                                                                    1\nUxcell a11102000ux0355 2N3906 General Purpose 3 Terminals PNP Transistors, 100 Piece                                                                                                                 1\nGreenForest Ergonomic Office Chair High Back Mesh with Adjustable Lumbar Support Headrest and Folded Mesh Back,No Tools Need for Install                                                             1\nPDP Titanfall 2 Official Marauder SRS Stereo Headset for PlayStation 4                                                                                                                               1\nName: count, Length: 85163, dtype: int64"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"# top 5\nproduct_transactions.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:42.504163Z","iopub.execute_input":"2024-11-05T01:50:42.504852Z","iopub.status.idle":"2024-11-05T01:50:42.513411Z","shell.execute_reply.started":"2024-11-05T01:50:42.504795Z","shell.execute_reply":"2024-11-05T01:50:42.512311Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"itemName\nPuppia Dog Harnesses                                                                    988\nKIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count    737\nKIND Bars, Caramel Almond and Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count           702\nKind Bars, Madagascar Vanilla Almond, Gluten Free, Low Sugar, 1.4oz                     664\nKIND Bars, Dark Chocolate Chili Almond, Gluten Free, 1.4 Ounce Bars, 12 Count           658\nVoyager All Weather No Pull Step-in Mesh Dog Harness Padded Vest                        559\nAmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate                      456\nAmazonBasics Padded Pet Bolster Bed                                                     440\nAmazonBasics Pet Training and Puppy Pads                                                426\nMilk-Bone Flavor Snacks Dog Treats                                                      408\nName: count, dtype: int64"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"# Displaying the first 5 comments (reviewText) for the item \"Puppia Dog Harnesses\" if available\npuppia_harness_reviews = df_4[df_4['itemName'] == \"Puppia Dog Harnesses\"]['reviewText'].dropna().head(50)\npuppia_harness_reviews","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:42.515182Z","iopub.execute_input":"2024-11-05T01:50:42.515648Z","iopub.status.idle":"2024-11-05T01:50:42.576273Z","shell.execute_reply.started":"2024-11-05T01:50:42.515596Z","shell.execute_reply":"2024-11-05T01:50:42.574826Z"}},"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"3250     If my little mutt wasn't as pudgy as I thought...\n3251                                       Great Product!!\n3252     Love this harness for our 7lb puppy! Originall...\n3443     Love this harness for our 7lb puppy! Originall...\n3444     If my little mutt wasn't as pudgy as I thought...\n3458                                       Great Product!!\n3506                                       Great Product!!\n3507     If my little mutt wasn't as pudgy as I thought...\n3509     Love this harness for our 7lb puppy! Originall...\n10073                                              Perfect\n10074                    Perfect for my puppy! & cute too!\n10075    Needs different clips for keeping it together ...\n10331    Needs different clips for keeping it together ...\n10333                    Perfect for my puppy! & cute too!\n10335                                              Perfect\n10893                                              Perfect\n10894    Needs different clips for keeping it together ...\n10901                    Perfect for my puppy! & cute too!\n12286                  Super product and great for my dog.\n12316    I bought three Puppia soft dog harnesses for o...\n12529    I bought three Puppia soft dog harnesses for o...\n12546                  Super product and great for my dog.\n13611                  Super product and great for my dog.\n13616    I bought three Puppia soft dog harnesses for o...\n14904    Works well,  I gave it a 4 star due to the fac...\n14933                                               Great!\n15034    Works well,  I gave it a 4 star due to the fac...\n15038                                               Great!\n16155    Works well,  I gave it a 4 star due to the fac...\n16181                                               Great!\n18272         the large does NOT fit a large dog. its TINY\n18273    Sizing is very small even when I went off the ...\n18599           Runs a little big for a small in the neck.\n19526           Runs a little big for a small in the neck.\n19551         the large does NOT fit a large dog. its TINY\n19552    Sizing is very small even when I went off the ...\n19637           Runs a little big for a small in the neck.\n19638    Sizing is very small even when I went off the ...\n19727         the large does NOT fit a large dog. its TINY\n24108                                                Small\n24110    Nice harness, looks great! Have gotten many co...\n24114                      Its sooo small!!! Not a medium.\n24273                                                Small\n24276    Nice harness, looks great! Have gotten many co...\n24280                      Its sooo small!!! Not a medium.\n24430                      Its sooo small!!! Not a medium.\n24455    Nice harness, looks great! Have gotten many co...\n24491                                                Small\n26017                        Perfect fit for my schnorkie!\n26018    Ive had this one before. I like it a lot. Nice...\nName: reviewText, dtype: object"},"metadata":{}}],"execution_count":100},{"cell_type":"code","source":"puppia_harness_reviews_positive = df_4[(df_4['itemName'] == \"Puppia Dog Harnesses\") & (df_4['rating'] == 2)]['reviewText'].dropna().head(10)\npuppia_harness_reviews_positive","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:42.577889Z","iopub.execute_input":"2024-11-05T01:50:42.578366Z","iopub.status.idle":"2024-11-05T01:50:42.634521Z","shell.execute_reply.started":"2024-11-05T01:50:42.578316Z","shell.execute_reply":"2024-11-05T01:50:42.633306Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"10075     Needs different clips for keeping it together ...\n10331     Needs different clips for keeping it together ...\n10894     Needs different clips for keeping it together ...\n12316     I bought three Puppia soft dog harnesses for o...\n12529     I bought three Puppia soft dog harnesses for o...\n13616     I bought three Puppia soft dog harnesses for o...\n88905     Followed the measurement chart and the harness...\n89869     Followed the measurement chart and the harness...\n90112     Followed the measurement chart and the harness...\n103730    I purchased this same harness a few years ago ...\nName: reviewText, dtype: object"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"# for our DEMO we are going to use at least three different items and category: \n# 1 - Puppia Dog Harnesses                                                                    988\n# 2 - KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count    737\n# 3 - AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate                      456\n\n# Now let's get the top 5 positives and negtive words!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:42.635995Z","iopub.execute_input":"2024-11-05T01:50:42.636413Z","iopub.status.idle":"2024-11-05T01:50:42.641314Z","shell.execute_reply.started":"2024-11-05T01:50:42.636374Z","shell.execute_reply":"2024-11-05T01:50:42.640080Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = list(stopwords.words(\"english\"))\n\ndef top_words_by_item(df, item_name, n=5):\n    \"\"\"\n    Extract the top positive and negative words for a specific item in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top words to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Top positive and negative words for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item\n    item_df = df[df['itemName'] == item_name]\n    \n    # Separate positive and negative reviews based on 'vote' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Define vectorizer once outside the conditionals\n    vectorizer = CountVectorizer(stop_words=stop_words)\n    \n    # Ensure that positive and negative reviews contain content\n    if positive_reviews.str.strip().eq(\"\").all():\n        top_positive_words = []\n    else:\n        positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n        positive_word_counts = positive_word_matrix.sum(axis=0).A1\n        positive_words = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n        top_positive_words = sorted(positive_words.items(), key=lambda x: x[1], reverse=True)[:n]\n\n    if negative_reviews.str.strip().eq(\"\").all():\n        top_negative_words = []\n    else:\n        negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n        negative_word_counts = negative_word_matrix.sum(axis=0).A1\n        negative_words = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n        top_negative_words = sorted(negative_words.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    return {\n        'top_positive_words': top_positive_words,\n        'top_negative_words': top_negative_words\n    }\n\n# Example Usage: Top words for specific items\ntop_words_harness = top_words_by_item(df_4, item_name=\"Puppia Dog Harnesses\", n=5)\nprint(\"Top words for Puppia Dog Harnesses:\", top_words_harness)\n\ntop_words_kind_bars = top_words_by_item(df_4, item_name=\"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\", n=5)\nprint(\"Top words for KIND Bars:\", top_words_kind_bars)\n\ntop_words_dog_crate = top_words_by_item(df_4, item_name=\"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\", n=5)\nprint(\"Top words for AmazonBasics Dog Crate:\", top_words_dog_crate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:50:42.643179Z","iopub.execute_input":"2024-11-05T01:50:42.643626Z","iopub.status.idle":"2024-11-05T01:51:02.932323Z","shell.execute_reply.started":"2024-11-05T01:50:42.643575Z","shell.execute_reply":"2024-11-05T01:51:02.930825Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop words for Puppia Dog Harnesses: {'top_positive_words': [('harness', 310), ('dog', 240), ('great', 213), ('fits', 190), ('fit', 174)], 'top_negative_words': [('dog', 123), ('harness', 96), ('small', 90), ('fit', 63), ('one', 42)]}\nTop words for KIND Bars: {'top_positive_words': [('bars', 166), ('great', 153), ('good', 132), ('love', 122), ('kind', 109)], 'top_negative_words': [('bars', 38), ('hard', 27), ('stale', 25), ('kind', 24), ('like', 16)]}\nTop words for AmazonBasics Dog Crate: {'top_positive_words': [('crate', 211), ('great', 164), ('dog', 125), ('easy', 122), ('size', 83)], 'top_negative_words': [('dog', 8), ('one', 8), ('crate', 7), ('get', 6), ('good', 5)]}\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"# now let's take a look of the best pos and neg comms:\n\ndef top_reviews_by_item(df, item_name, n=5):\n    \"\"\"\n    Extract the top positive and negative reviews for a specific item in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top reviews to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Top positive and negative reviews for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item\n    item_df = df[df['itemName'] == item_name]\n    \n    # Separate positive and negative reviews based on 'vote' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].dropna().head(n).tolist()\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].dropna().head(n).tolist()\n    \n    return {\n        'top_positive_reviews': positive_reviews,\n        'top_negative_reviews': negative_reviews\n    }\n\n# Example Usage: Top reviews for specific items\ntop_reviews_harness = top_reviews_by_item(df_4, item_name=\"Puppia Dog Harnesses\", n=5)\nprint(\"Top reviews for Puppia Dog Harnesses:\", top_reviews_harness)\n\ntop_reviews_kind_bars = top_reviews_by_item(df_4, item_name=\"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\", n=5)\nprint(\"Top reviews for KIND Bars:\", top_reviews_kind_bars)\n\ntop_reviews_dog_crate = top_reviews_by_item(df_4, item_name=\"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\", n=5)\nprint(\"Top reviews for AmazonBasics Dog Crate:\", top_reviews_dog_crate)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:51:02.933891Z","iopub.execute_input":"2024-11-05T01:51:02.934365Z","iopub.status.idle":"2024-11-05T01:51:03.117441Z","shell.execute_reply.started":"2024-11-05T01:51:02.934314Z","shell.execute_reply":"2024-11-05T01:51:03.116212Z"}},"outputs":[{"name":"stdout","text":"Top reviews for Puppia Dog Harnesses: {'top_positive_reviews': ['If my little mutt wasn\\'t as pudgy as I thought she was this would fit perfectly...She seems to be a \"tweener\"..she\\'s between a medium and large.  Other than that this is a very well constructed harness.', 'Great Product!!', \"Love this harness for our 7lb puppy! Originally got the XS- because she's only a few months old, but her head was too big to slip through easily. the Small is a better fir for over her head, we had to tighten the belly strap all the way since it's a little big- but she'll grow into it nicley- really well made!\", \"Love this harness for our 7lb puppy! Originally got the XS- because she's only a few months old, but her head was too big to slip through easily. the Small is a better fir for over her head, we had to tighten the belly strap all the way since it's a little big- but she'll grow into it nicley- really well made!\", 'If my little mutt wasn\\'t as pudgy as I thought she was this would fit perfectly...She seems to be a \"tweener\"..she\\'s between a medium and large.  Other than that this is a very well constructed harness.'], 'top_negative_reviews': ['Needs different clips for keeping it together because the clip broke.', 'Needs different clips for keeping it together because the clip broke.', 'Needs different clips for keeping it together because the clip broke.', 'I bought three Puppia soft dog harnesses for our dogs.  The XXL and medium sizes fit as advertised.  The XL size was way too small for our female Doberman.  Her chest girth is 28 and according to Puppia the XL should fit dogs with a chest girth between 22.8-33.  It was probably labeled incorrectly as an XL.  The quality appears to be good but sizing was not correct.  I could see right away that it wouldnt fit.  I put the XXL on her, which was too big.', 'I bought three Puppia soft dog harnesses for our dogs.  The XXL and medium sizes fit as advertised.  The XL size was way too small for our female Doberman.  Her chest girth is 28 and according to Puppia the XL should fit dogs with a chest girth between 22.8-33.  It was probably labeled incorrectly as an XL.  The quality appears to be good but sizing was not correct.  I could see right away that it wouldnt fit.  I put the XXL on her, which was too big.']}\nTop reviews for KIND Bars: {'top_positive_reviews': ['great healthy snacks on the go', 'great', \"I find it hard to 'commit' to a 12 single flavor of KIND bars, so I like this variety pack option which gives some variety. KIND bars are nice tasting, but not my go-to snack; the ingredients are great, simple, clean, but for me it's not a filling snack for the ~200 calories. I would like best to find the mini bar packs on Amazon at a decent price; I rarely even find them in physical stores.\\nLike most nut bars the bars are sticky. I don't consider KIND bars good on the go bars; the honey and chocolate coatings melt easily.\\nThe nuts in the bars are good quality and seem quite fresh, but don't pack tons of flavor. The bars I received in December 2017 expire in November 2018. With most nut bars the issue is that depending on expiration date and storing conditions prior to purchase, you can get hit or miss (e.g. stale tasting nut bars), no matter if you purchase from Amazon or the store.\\nI like that they list the nuts in the order of predominance in the bar, so you can choose your favorite type of nuts.\\nAll flavors in the variety pack tasted good. I enjoy they are not very sweet. The 'spices' (cinnamon, maple) are quite mild, would preferred a stronger flavor.\\n\\nThe box was delivered in decent condition, in a plastic bag; the box was slightly dented (since the bag probably didn't protect it from careless delivery), but the bars were in perfect shape.\\n\\nIndividual bar review:\\nDark Chocolate Nuts & Sea Salt - This bar has a rich dark chocolate drizzle and bottom coating; I love it's not a sweet bar, so I can enjoy the dark chocolate and the delicious combination with sea salt. The peanuts are predominant in this bar as flavor, although almonds are listed first.\\nDark Chocolate Cinnamon Pecan - This bar has a rich dark chocolate drizzle and bottom coating; I love it's not a sweet bar, so I can enjoy the dark chocolate. The cinnamon flavor is mild, barely noticeable. I liked that the pecan content is high, and I could taste them over the almonds and peanuts.\\nMaple Glazed Pecan & Sea Salt - This is mostly an almonds bar, with some peanuts and pecans. Again, not very sweet, and the sea salt is nice addition to the flavor. The maple syrup flavor is mild.\\n\\nOther flavors I tried:\\nKind Plus Dark Chocolate Cherry Cashew - I really enjoyed the abundance of cherries and cashews, but I could also taste the raisins. The chocolate bottom melts very easily, this bar needs to be stored in a cool place; the chocolate is not the best tasting. I didn't like how sweet this bar is, the ingredient lists contains dry fruits, sugar, glucose syrup... more sweeteners than needed.\", 'As described', 'Delicious'], 'top_negative_reviews': ['Received a wrapper with no bar in it.', 'Stale. Stale. Stale.', 'never buy these, i lost a tooth to this junk...i wish i could file a suit for losing a tooth...NOT KIND', 'When this arrived, the package inside the box was opened and there were only 11 bars instead of 12.', 'Poor quality control! Ive been ordering these through Amazon for the past few months because I cant find this flavor in local stores. Unfortunately, the last two boxes that I have received taste like the product melted in a warehouse and then re-formed. As a result, the consistency is totally off (very hard and sticky), which makes the bar way less enjoyable. Though they have not been expired, they essentially taste that way.']}\nTop reviews for AmazonBasics Dog Crate: {'top_positive_reviews': ['HUGE! But great quality Nd super cheap compared to whats out there... they are all the same. Save your money and buy this!', 'works great.', 'Great quality, easy set up & take down which is nice for traveling and bringing it with us', 'A bit too small for me', 'It is a great cage to use as time out for barking too much. I only gave 4 stars because it was almost impossible to get to first base. The instructions which are stuck on the inside of the folded crate make it impossible to read how to get the first piece open. When I figured out how to get the first part apart the instructions were not helpful. Just remember that you will have to find a clip to unlock the crate.'], 'top_negative_reviews': ['We love this crate. However, the bottom plastic tray piece arrived cracked/broken on one corner. Disappointing.', 'Not very strong my 8 month old puppy managed to bend a side and escape', \"Who knew a 9 month puppy would climb up the sides like a ladder. Once on top his little legs were falling through. Don't get unless you get a cover to go with it.\", 'meh', 'Our dog tore through this on the first day. Would work well if you pup just sleeps in it. Not good for anxious dogs that want to break out.']}\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\ndef top_bigrams_by_item(df, item_name, n=5):\n    \"\"\"\n    Extract the top positive and negative bigrams for a specific item in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top bigrams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Top positive and negative bigrams for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item\n    item_df = df[df['itemName'] == item_name]\n    \n    # Separate positive and negative reviews based on 'vote' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and bigrams (2-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2, 2), max_df=0.85)\n    \n    # Positive bigrams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_bigrams = sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative bigrams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_bigrams = sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    return {\n        'top_positive_bigrams': top_positive_bigrams,\n        'top_negative_bigrams': top_negative_bigrams\n    }\n\n# List of item names to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Loop through each item and get top bigrams\nfor item in item_names:\n    bigrams = top_bigrams_by_item(df_4, item_name=item, n=10)\n    print(f\"Top bigrams for {item}:\")\n    print(\"Positive Bigrams:\", bigrams['top_positive_bigrams'])\n    print(\"Negative Bigrams:\", bigrams['top_negative_bigrams'])\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:51:03.118990Z","iopub.execute_input":"2024-11-05T01:51:03.119383Z","iopub.status.idle":"2024-11-05T01:51:23.443937Z","shell.execute_reply.started":"2024-11-05T01:51:03.119346Z","shell.execute_reply":"2024-11-05T01:51:23.442816Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop bigrams for Puppia Dog Harnesses:\nPositive Bigrams: [('easy put', 9.229998361334907), ('perfect fit', 8.305259415896758), ('well made', 7.119726239445134), ('great harness', 6.1433980477882315), ('fits great', 6.117566834734155), ('great quality', 5.8641802012273025), ('works great', 5.7964646994700075), ('great price', 5.6795568779879), ('comfortable dog', 5.422499542716795), ('fits well', 5.129372155070933)]\nNegative Bigrams: [('large dog', 4.241086548762492), ('small medium', 4.168950991813728), ('way big', 3.405831484947769), ('innacurate size', 3.0), ('much small', 2.952840786365443), ('fit dog', 2.9232809307123815), ('put dog', 2.4174207100216414), ('medium large', 2.3291458835522985), ('sooo small', 2.3237780411320745), ('large fit', 2.3001418079761424)]\n\n\nTop bigrams for KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count:\nPositive Bigrams: [('kind bars', 11.77936199495297), ('great snack', 7.3137141365398115), ('love bars', 7.309168223136466), ('great taste', 6.10807641650759), ('favorite kind', 5.689035003737924), ('kind bar', 5.569953408958638), ('dark chocolate', 4.895960518664143), ('taste great', 4.818844577838677), ('gluten free', 4.60735401709165), ('best flavor', 4.542265799719226)]\nNegative Bigrams: [('tasted stale', 1.7474995481565347), ('bars stale', 1.742019617315751), ('kind bars', 1.6876736979165123), ('rock hard', 1.4272297661728581), ('hard rock', 1.23877591499692), ('stale hard', 1.042271828291763), ('hard brick', 1.0), ('stale stale', 1.0), ('taste good', 0.8601009458788252), ('hard rocks', 0.8355304360507816)]\n\n\nTop bigrams for AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate:\nPositive Bigrams: [('great price', 9.822620391665751), ('great crate', 6.5035577976166), ('easy assemble', 5.5605206913673735), ('great quality', 5.527718383212117), ('easy put', 5.00198497983131), ('put together', 4.795219908690464), ('easy set', 4.736068963481285), ('well made', 3.846504279564874), ('perfect size', 3.537182951752289), ('works great', 3.5207685741502543)]\nNegative Bigrams: [('breaks easily', 1.0), ('worth effort', 1.0), ('month old', 0.6979043409032618), ('boxer tore', 0.4167237888361141), ('crate apart', 0.4167237888361141), ('lab boxer', 0.4167237888361141), ('old lab', 0.4167237888361141), ('tore crate', 0.4167237888361141), ('bend side', 0.38466031138192547), ('managed bend', 0.38466031138192547)]\n\n\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"# now have unique outcomes: We're using this one\n\n# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\ndef top_unique_bigrams_by_item(df, item_name, n=5):\n    \"\"\"\n    Extract the top unique positive and negative bigrams for a specific item in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top bigrams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Unique top positive and negative bigrams for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item\n    item_df = df[df['itemName'] == item_name]\n    \n    # Separate positive and negative reviews based on 'rating' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and bigrams (2-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2, 2), max_df=0.85)\n    \n    # Positive bigrams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_bigrams = sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative bigrams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_bigrams = sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Remove overlapping bigrams to ensure uniqueness\n    positive_set = set(word for word, count in top_positive_bigrams)\n    negative_set = set(word for word, count in top_negative_bigrams)\n    \n    unique_positive_bigrams = [(word, count) for word, count in top_positive_bigrams if word not in negative_set]\n    unique_negative_bigrams = [(word, count) for word, count in top_negative_bigrams if word not in positive_set]\n    \n    return {\n        'top_positive_bigrams': unique_positive_bigrams[:n],\n        'top_negative_bigrams': unique_negative_bigrams[:n]\n    }\n\n# List of item names to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Loop through each item and get top unique bigrams\nfor item in item_names:\n    bigrams = top_unique_bigrams_by_item(df_4, item_name=item, n=10)\n    print(f\"Top unique bigrams for {item}:\")\n    print(\"Positive Bigrams:\", bigrams['top_positive_bigrams'])\n    print(\"Negative Bigrams:\", bigrams['top_negative_bigrams'])\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:51:23.445262Z","iopub.execute_input":"2024-11-05T01:51:23.445594Z","iopub.status.idle":"2024-11-05T01:51:43.777918Z","shell.execute_reply.started":"2024-11-05T01:51:23.445560Z","shell.execute_reply":"2024-11-05T01:51:43.776671Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop unique bigrams for Puppia Dog Harnesses:\nPositive Bigrams: [('easy put', 9.229998361334907), ('perfect fit', 8.305259415896758), ('well made', 7.119726239445134), ('great harness', 6.1433980477882315), ('fits great', 6.117566834734155), ('great quality', 5.8641802012273025), ('works great', 5.7964646994700075), ('great price', 5.6795568779879), ('comfortable dog', 5.422499542716795), ('fits well', 5.129372155070933)]\nNegative Bigrams: [('large dog', 4.241086548762492), ('small medium', 4.168950991813728), ('way big', 3.405831484947769), ('innacurate size', 3.0), ('much small', 2.952840786365443), ('fit dog', 2.9232809307123815), ('put dog', 2.4174207100216414), ('medium large', 2.3291458835522985), ('sooo small', 2.3237780411320745), ('large fit', 2.3001418079761424)]\n\n\nTop unique bigrams for KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count:\nPositive Bigrams: [('great snack', 7.3137141365398115), ('love bars', 7.309168223136466), ('great taste', 6.10807641650759), ('favorite kind', 5.689035003737924), ('kind bar', 5.569953408958638), ('dark chocolate', 4.895960518664143), ('taste great', 4.818844577838677), ('gluten free', 4.60735401709165), ('best flavor', 4.542265799719226)]\nNegative Bigrams: [('tasted stale', 1.7474995481565347), ('bars stale', 1.742019617315751), ('rock hard', 1.4272297661728581), ('hard rock', 1.23877591499692), ('stale hard', 1.042271828291763), ('hard brick', 1.0), ('stale stale', 1.0), ('taste good', 0.8601009458788252), ('hard rocks', 0.8355304360507816)]\n\n\nTop unique bigrams for AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate:\nPositive Bigrams: [('great price', 9.822620391665751), ('great crate', 6.5035577976166), ('easy assemble', 5.5605206913673735), ('great quality', 5.527718383212117), ('easy put', 5.00198497983131), ('put together', 4.795219908690464), ('easy set', 4.736068963481285), ('well made', 3.846504279564874), ('perfect size', 3.537182951752289), ('works great', 3.5207685741502543)]\nNegative Bigrams: [('breaks easily', 1.0), ('worth effort', 1.0), ('month old', 0.6979043409032618), ('boxer tore', 0.4167237888361141), ('crate apart', 0.4167237888361141), ('lab boxer', 0.4167237888361141), ('old lab', 0.4167237888361141), ('tore crate', 0.4167237888361141), ('bend side', 0.38466031138192547), ('managed bend', 0.38466031138192547)]\n\n\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"#  Now only using the data where Amazon_verified = 'Verified'\n\n# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\ndef top_unique_bigrams_by_item_verified(df, item_name, n=5):\n    \"\"\"\n    Extract the top unique positive and negative bigrams for a specific item in a dataset,\n    considering only rows where Amazon_verified is \"Verified\".\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top bigrams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Unique top positive and negative bigrams for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item and verified reviews\n    item_df = df[(df['itemName'] == item_name) & (df['Amazon_verified'] == \"Verified\")]\n    \n    # Separate positive and negative reviews based on 'rating' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and bigrams (2-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2, 2), max_df=0.85)\n    \n    # Positive bigrams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_bigrams = sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative bigrams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_bigrams = sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Remove overlapping bigrams to ensure uniqueness\n    positive_set = set(word for word, count in top_positive_bigrams)\n    negative_set = set(word for word, count in top_negative_bigrams)\n    \n    unique_positive_bigrams = [(word, count) for word, count in top_positive_bigrams if word not in negative_set]\n    unique_negative_bigrams = [(word, count) for word, count in top_negative_bigrams if word not in positive_set]\n    \n    return {\n        'top_positive_bigrams': unique_positive_bigrams[:n],\n        'top_negative_bigrams': unique_negative_bigrams[:n]\n    }\n\n# List of item names to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Loop through each item and get top unique bigrams\nfor item in item_names:\n    bigrams = top_unique_bigrams_by_item_verified(df_4, item_name=item, n=10)\n    print(f\"Top unique bigrams for {item}:\")\n    print(\"Positive Bigrams:\", bigrams['top_positive_bigrams'])\n    print(\"Negative Bigrams:\", bigrams['top_negative_bigrams'])\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:51:43.779607Z","iopub.execute_input":"2024-11-05T01:51:43.780095Z","iopub.status.idle":"2024-11-05T01:52:04.175962Z","shell.execute_reply.started":"2024-11-05T01:51:43.780044Z","shell.execute_reply":"2024-11-05T01:52:04.174778Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop unique bigrams for Puppia Dog Harnesses:\nPositive Bigrams: [('easy put', 6.45615521004141), ('perfect fit', 5.2582768948384935), ('fits well', 4.340687685093655), ('good price', 3.965540497592226), ('well made', 3.9118036331256314), ('small dog', 3.759765058935519), ('fit perfectly', 3.711476233705194), ('good harness', 3.616027958379303), ('looks great', 3.5934487043727774), ('great quality', 3.0765291166618107)]\nNegative Bigrams: [('innacurate size', 3.0), ('large dog', 2.888746597803891), ('way big', 2.4339700739445354), ('small medium', 2.3033327249943687), ('large fit', 2.2153715255723414), ('medium large', 2.176987397049947), ('accurate return', 2.121320343559643), ('bog little', 2.121320343559643), ('little one', 2.121320343559643), ('made pup', 2.121320343559643)]\n\n\nTop unique bigrams for KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count:\nPositive Bigrams: [('great snack', 7.301941977923804), ('love bars', 7.267735736716858), ('great taste', 5.788215368820671), ('favorite kind', 5.680231652086358), ('kind bar', 5.555980079575309), ('taste great', 4.814946848756669), ('dark chocolate', 4.705435021995044), ('best flavor', 4.54092665177269), ('gluten free', 4.297155440093188)]\nNegative Bigrams: [('bars stale', 1.7417836576686108), ('rock hard', 1.4258783635543324), ('tasted stale', 1.3778575957303936), ('hard rock', 1.2369507097137955), ('stale hard', 1.0415724864793232), ('hard brick', 1.0), ('stale stale', 1.0), ('taste good', 0.8594717704300323), ('hard rocks', 0.8349058209280291)]\n\n\nTop unique bigrams for AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate:\nPositive Bigrams: [('great price', 9.399862778160738), ('great crate', 5.1892918159932435), ('easy set', 4.651392696312314), ('great quality', 4.51641646962901), ('easy assemble', 4.505159140549728), ('easy put', 3.9544517576224254), ('put together', 3.7322971962569347), ('well made', 3.3266362614238156), ('perfect size', 3.120610446706845), ('good price', 2.9880364314010026)]\nNegative Bigrams: [('breaks easily', 1.0), ('worth effort', 1.0), ('3rd day', 0.31622776601683794), ('70lb gsd', 0.31622776601683794), ('7month 70lb', 0.31622776601683794), ('broke 3rd', 0.31622776601683794), ('crate give', 0.31622776601683794), ('day 7month', 0.31622776601683794), ('dog broke', 0.31622776601683794), ('give peace', 0.31622776601683794)]\n\n\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"# Now only using the data where Amazon_verified_leverage = 'Verified'\n\n# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\ndef top_unique_bigrams_by_item_verified_leverage(df, item_name, n=5):\n    \"\"\"\n    Extract the top unique positive and negative bigrams for a specific item in a dataset,\n    considering only rows where Amazon_verified_leverage is \"Verified\".\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top bigrams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Unique top positive and negative bigrams for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item and leverage-verified reviews\n    item_df = df[(df['itemName'] == item_name) & (df['Amazon_verified_leverage'] == \"Verified\")]\n    \n    # Separate positive and negative reviews based on 'rating' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and bigrams (2-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2, 2), max_df=0.85)\n    \n    # Positive bigrams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_bigrams = sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative bigrams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_bigrams = sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Remove overlapping bigrams to ensure uniqueness\n    positive_set = set(word for word, count in top_positive_bigrams)\n    negative_set = set(word for word, count in top_negative_bigrams)\n    \n    unique_positive_bigrams = [(word, count) for word, count in top_positive_bigrams if word not in negative_set]\n    unique_negative_bigrams = [(word, count) for word, count in top_negative_bigrams if word not in positive_set]\n    \n    return {\n        'top_positive_bigrams': unique_positive_bigrams[:n],\n        'top_negative_bigrams': unique_negative_bigrams[:n]\n    }\n\n# List of item names to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Loop through each item and get top unique bigrams\nfor item in item_names:\n    bigrams = top_unique_bigrams_by_item_verified_leverage(df_4, item_name=item, n=10)\n    print(f\"Top unique bigrams for {item}:\")\n    print(\"Positive Bigrams:\", bigrams['top_positive_bigrams'])\n    print(\"Negative Bigrams:\", bigrams['top_negative_bigrams'])\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:52:04.177594Z","iopub.execute_input":"2024-11-05T01:52:04.178094Z","iopub.status.idle":"2024-11-05T01:52:24.581128Z","shell.execute_reply.started":"2024-11-05T01:52:04.178041Z","shell.execute_reply":"2024-11-05T01:52:24.579959Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop unique bigrams for Puppia Dog Harnesses:\nPositive Bigrams: [('easy put', 9.229998361334907), ('perfect fit', 8.305259415896758), ('well made', 7.119726239445134), ('great harness', 6.1433980477882315), ('fits great', 6.117566834734155), ('great quality', 5.8641802012273025), ('works great', 5.7964646994700075), ('great price', 5.6795568779879), ('comfortable dog', 5.422499542716795), ('fits well', 5.129372155070933)]\nNegative Bigrams: [('large dog', 4.241086548762492), ('small medium', 4.168950991813728), ('way big', 3.405831484947769), ('innacurate size', 3.0), ('much small', 2.952840786365443), ('fit dog', 2.9232809307123815), ('put dog', 2.4174207100216414), ('medium large', 2.3291458835522985), ('sooo small', 2.3237780411320745), ('large fit', 2.3001418079761424)]\n\n\nTop unique bigrams for KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count:\nPositive Bigrams: [('great snack', 7.308656362687716), ('love bars', 7.288842451686053), ('great taste', 6.105106736443342), ('favorite kind', 5.684783477060537), ('kind bar', 5.564519755984933), ('taste great', 4.817395394953788), ('dark chocolate', 4.714462216895877), ('gluten free', 4.604583747802637), ('best flavor', 4.541778841114937)]\nNegative Bigrams: [('bars stale', 1.7419027214778349), ('rock hard', 1.4265605361576963), ('tasted stale', 1.3779448171147404), ('hard rock', 1.237871938223889), ('stale hard', 1.0419254810600946), ('hard brick', 1.0), ('stale stale', 1.0), ('taste good', 0.8597893351780141), ('hard rocks', 0.8352210791868551)]\n\n\nTop unique bigrams for AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate:\nPositive Bigrams: [('great price', 9.612223874620392), ('great crate', 5.618204158761921), ('easy assemble', 5.239375555100442), ('easy put', 4.836537613697361), ('easy set', 4.695350797124304), ('put together', 4.624638048793935), ('great quality', 4.535838000736652), ('well made', 3.7869037988520233), ('perfect size', 3.329653687851494), ('good price', 3.2091717032800315)]\nNegative Bigrams: [('breaks easily', 1.0), ('worth effort', 1.0), ('bend side', 0.37796447300922725), ('managed bend', 0.37796447300922725), ('month old', 0.37796447300922725), ('old puppy', 0.37796447300922725), ('puppy managed', 0.37796447300922725), ('side escape', 0.37796447300922725), ('strong month', 0.37796447300922725), ('3rd day', 0.31622776601683794)]\n\n\n","output_type":"stream"}],"execution_count":108},{"cell_type":"code","source":"# Download required NLTK data\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\n# Define the function to extract unique bigrams\ndef top_unique_bigrams_by_item_verified_leverage(df, item_name, n=5):\n    item_df = df[(df['itemName'] == item_name) & (df['Amazon_verified_leverage'] == \"Verified\")]\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2, 2), max_df=0.85)\n\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_bigrams = sorted(positive_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_bigrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_bigrams = sorted(negative_bigrams.items(), key=lambda x: x[1], reverse=True)[:n]\n\n    positive_set = set(word for word, count in top_positive_bigrams)\n    negative_set = set(word for word, count in top_negative_bigrams)\n\n    unique_positive_bigrams = [word for word, count in top_positive_bigrams if word not in negative_set]\n    unique_negative_bigrams = [word for word, count in top_negative_bigrams if word not in positive_set]\n    \n    return {\n        'top_positive_bigrams': unique_positive_bigrams if unique_positive_bigrams else \"TBC\",\n        'top_negative_bigrams': unique_negative_bigrams if unique_negative_bigrams else \"TBC\"\n    }\n\n# Initialize new columns with default value \"TBC\"\ndf_4['Positive Phrases'] = \"TBC\"\ndf_4['Negative Phrases'] = \"TBC\"\n\n# Define the items to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Update each row based on the item name and verified leverage bigrams\nfor item in item_names:\n    bigrams = top_unique_bigrams_by_item_verified_leverage(df_4, item_name=item, n=10)\n    df_4.loc[df_4['itemName'] == item, 'Positive Phrases'] = df_4.loc[df_4['itemName'] == item].apply(\n        lambda x: bigrams['top_positive_bigrams'], axis=1\n    )\n    df_4.loc[df_4['itemName'] == item, 'Negative Phrases'] = df_4.loc[df_4['itemName'] == item].apply(\n        lambda x: bigrams['top_negative_bigrams'], axis=1\n    )\n\n# Display the unique items along with their Positive and Negative Phrases\n# Here, we display only one sample row per item to avoid duplications visually\n\nfor item in item_names:\n    sample_row = df_4[df_4['itemName'] == item][['itemName', 'Positive Phrases', 'Negative Phrases']].iloc[0]\n    print(f\"Item Name: {sample_row['itemName']}\")\n    print(\"Positive Phrases:\", sample_row['Positive Phrases'])\n    print(\"Negative Phrases:\", sample_row['Negative Phrases'])\n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:52:24.582465Z","iopub.execute_input":"2024-11-05T01:52:24.582831Z","iopub.status.idle":"2024-11-05T01:52:45.842356Z","shell.execute_reply.started":"2024-11-05T01:52:24.582787Z","shell.execute_reply":"2024-11-05T01:52:45.841191Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nItem Name: Puppia Dog Harnesses\nPositive Phrases: ['easy put', 'perfect fit', 'well made', 'great harness', 'fits great', 'great quality', 'works great', 'great price', 'comfortable dog', 'fits well']\nNegative Phrases: ['large dog', 'small medium', 'way big', 'innacurate size', 'much small', 'fit dog', 'put dog', 'medium large', 'sooo small', 'large fit']\n\n\nItem Name: KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\nPositive Phrases: ['great snack', 'love bars', 'great taste', 'favorite kind', 'kind bar', 'taste great', 'dark chocolate', 'gluten free', 'best flavor']\nNegative Phrases: ['bars stale', 'rock hard', 'tasted stale', 'hard rock', 'stale hard', 'hard brick', 'stale stale', 'taste good', 'hard rocks']\n\n\nItem Name: AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\nPositive Phrases: ['great price', 'great crate', 'easy assemble', 'easy put', 'easy set', 'put together', 'great quality', 'well made', 'perfect size', 'good price']\nNegative Phrases: ['breaks easily', 'worth effort', 'bend side', 'managed bend', 'month old', 'old puppy', 'puppy managed', 'side escape', 'strong month', '3rd day']\n\n\n","output_type":"stream"}],"execution_count":109},{"cell_type":"code","source":"df_4.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:52:45.843589Z","iopub.execute_input":"2024-11-05T01:52:45.843942Z","iopub.status.idle":"2024-11-05T01:52:45.864564Z","shell.execute_reply.started":"2024-11-05T01:52:45.843905Z","shell.execute_reply":"2024-11-05T01:52:45.863418Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"          userName                                           itemName  \\\n0  Amazon Customer  Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...   \n1            Carla  Prince of Peace Organic Tea, Oolong, 100 Tea Bags   \n2           Jaclyn  Pet Champion Adjustable No-Pull Harness, Colla...   \n3     Christinne M  Koh-I-Noor Progresso Woodless Colored 24-Penci...   \n6          patrick  Blue Buffalo Life Protection Formula Natural P...   \n\n                                         description            brand  \\\n0  [\"Made from deliciously decadent ingredients, ...        Toblerone   \n1  ['Prince of Peace Enterprises, Inc., founded i...  Prince Of Peace   \n2  [\"The Pet Champion Large/ Extra Large 22-36 in...     Pet Champion   \n3  ['Koh-I-Noor Progresso Woodless Colored 24-Pen...       KOH-I-NOOR   \n6  ['Because puppyhood is such an important stage...     Blue Buffalo   \n\n                   category  price  rating  reviewTime  \\\n0              Prime_Pantry   1.63     5.0  2018-01-01   \n1  Grocery_and_Gourmet_Food   6.40     5.0  2018-01-01   \n2              Pet_Supplies   7.99     5.0  2018-01-01   \n3    Arts_Crafts_and_Sewing  14.18     5.0  2018-01-01   \n6              Pet_Supplies  28.99     5.0  2018-01-01   \n\n                                             summary  \\\n0                                         Five Stars   \n1                                         Five Stars   \n2  she has an odd shape chest and her pull over h...   \n3                                           Loving!!   \n6  ... and has had no problems with this food - B...   \n\n                                          reviewText  vote Amazon_verified  \\\n0           super smooth and yummy with crunchy bits     0        Verified   \n1                               Perfect for kombucha     0        Verified   \n2  Finally a harness that fits my puppy. I really...     0        Verified   \n3  I LOVE THEM!! I bought them at Micheals our of...     0    Not Verified   \n6  My 1 year old husky loves it - healthy and has...     0        Verified   \n\n  Amazon_verified_leverage Positive Phrases Negative Phrases  \n0                 Verified              TBC              TBC  \n1                 Verified              TBC              TBC  \n2                 Verified              TBC              TBC  \n3             Not Verified              TBC              TBC  \n6                 Verified              TBC              TBC  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userName</th>\n      <th>itemName</th>\n      <th>description</th>\n      <th>brand</th>\n      <th>category</th>\n      <th>price</th>\n      <th>rating</th>\n      <th>reviewTime</th>\n      <th>summary</th>\n      <th>reviewText</th>\n      <th>vote</th>\n      <th>Amazon_verified</th>\n      <th>Amazon_verified_leverage</th>\n      <th>Positive Phrases</th>\n      <th>Negative Phrases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amazon Customer</td>\n      <td>Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...</td>\n      <td>[\"Made from deliciously decadent ingredients, ...</td>\n      <td>Toblerone</td>\n      <td>Prime_Pantry</td>\n      <td>1.63</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>super smooth and yummy with crunchy bits</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carla</td>\n      <td>Prince of Peace Organic Tea, Oolong, 100 Tea Bags</td>\n      <td>['Prince of Peace Enterprises, Inc., founded i...</td>\n      <td>Prince Of Peace</td>\n      <td>Grocery_and_Gourmet_Food</td>\n      <td>6.40</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Five Stars</td>\n      <td>Perfect for kombucha</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jaclyn</td>\n      <td>Pet Champion Adjustable No-Pull Harness, Colla...</td>\n      <td>[\"The Pet Champion Large/ Extra Large 22-36 in...</td>\n      <td>Pet Champion</td>\n      <td>Pet_Supplies</td>\n      <td>7.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>she has an odd shape chest and her pull over h...</td>\n      <td>Finally a harness that fits my puppy. I really...</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christinne M</td>\n      <td>Koh-I-Noor Progresso Woodless Colored 24-Penci...</td>\n      <td>['Koh-I-Noor Progresso Woodless Colored 24-Pen...</td>\n      <td>KOH-I-NOOR</td>\n      <td>Arts_Crafts_and_Sewing</td>\n      <td>14.18</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>Loving!!</td>\n      <td>I LOVE THEM!! I bought them at Micheals our of...</td>\n      <td>0</td>\n      <td>Not Verified</td>\n      <td>Not Verified</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>patrick</td>\n      <td>Blue Buffalo Life Protection Formula Natural P...</td>\n      <td>['Because puppyhood is such an important stage...</td>\n      <td>Blue Buffalo</td>\n      <td>Pet_Supplies</td>\n      <td>28.99</td>\n      <td>5.0</td>\n      <td>2018-01-01</td>\n      <td>... and has had no problems with this food - B...</td>\n      <td>My 1 year old husky loves it - healthy and has...</td>\n      <td>0</td>\n      <td>Verified</td>\n      <td>Verified</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"inter_cols2 =  ['itemName', 'Positive Phrases', 'Negative Phrases']\ndf_4[inter_cols2].head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:52:45.866058Z","iopub.execute_input":"2024-11-05T01:52:45.866439Z","iopub.status.idle":"2024-11-05T01:52:45.905906Z","shell.execute_reply.started":"2024-11-05T01:52:45.866392Z","shell.execute_reply":"2024-11-05T01:52:45.904807Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"                                             itemName Positive Phrases  \\\n0   Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...              TBC   \n1   Prince of Peace Organic Tea, Oolong, 100 Tea Bags              TBC   \n2   Pet Champion Adjustable No-Pull Harness, Colla...              TBC   \n3   Koh-I-Noor Progresso Woodless Colored 24-Penci...              TBC   \n6   Blue Buffalo Life Protection Formula Natural P...              TBC   \n7   Squishy Face Studio Flirt Pole V2 with Braided...              TBC   \n8                  Penn Plax Net Breeder for Aquarium              TBC   \n9   PetSafe Freedom Aluminum Patio Panel Sliding G...              TBC   \n10  Vet Recommended Pet ID Tag Dog and Cat Persona...              TBC   \n11  Avery Removable Print or Write Labels, 1.5 x 3...              TBC   \n\n   Negative Phrases  \n0               TBC  \n1               TBC  \n2               TBC  \n3               TBC  \n6               TBC  \n7               TBC  \n8               TBC  \n9               TBC  \n10              TBC  \n11              TBC  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>itemName</th>\n      <th>Positive Phrases</th>\n      <th>Negative Phrases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Toblerone Swiss Milk Chocolate Bar, Crunchy Sa...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Prince of Peace Organic Tea, Oolong, 100 Tea Bags</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pet Champion Adjustable No-Pull Harness, Colla...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Koh-I-Noor Progresso Woodless Colored 24-Penci...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Blue Buffalo Life Protection Formula Natural P...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Squishy Face Studio Flirt Pole V2 with Braided...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Penn Plax Net Breeder for Aquarium</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PetSafe Freedom Aluminum Patio Panel Sliding G...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Vet Recommended Pet ID Tag Dog and Cat Persona...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Avery Removable Print or Write Labels, 1.5 x 3...</td>\n      <td>TBC</td>\n      <td>TBC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"# for tableau\ndf_4[inter_cols2].to_excel('nlp.xlsx') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:52:45.907316Z","iopub.execute_input":"2024-11-05T01:52:45.907669Z","iopub.status.idle":"2024-11-05T01:53:52.149453Z","shell.execute_reply.started":"2024-11-05T01:52:45.907633Z","shell.execute_reply":"2024-11-05T01:53:52.148309Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\ndef top_unique_threegrams_by_item(df, item_name, n=5):\n    \"\"\"\n    Extract the top unique positive and negative three-grams for a specific item in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top three-grams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Unique top positive and negative three-grams for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item\n    item_df = df[df['itemName'] == item_name]\n    \n    # Separate positive and negative reviews based on 'rating' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and three-grams (3-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(3, 3), max_df=0.85)\n    \n    # Positive three-grams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_threegrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_threegrams = sorted(positive_threegrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative three-grams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_threegrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_threegrams = sorted(negative_threegrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Remove overlapping three-grams to ensure uniqueness\n    positive_set = set(word for word, count in top_positive_threegrams)\n    negative_set = set(word for word, count in top_negative_threegrams)\n    \n    unique_positive_threegrams = [(word, count) for word, count in top_positive_threegrams if word not in negative_set]\n    unique_negative_threegrams = [(word, count) for word, count in top_negative_threegrams if word not in positive_set]\n    \n    return {\n        'top_positive_threegrams': unique_positive_threegrams[:n],\n        'top_negative_threegrams': unique_negative_threegrams[:n]\n    }\n\n# List of item names to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Loop through each item and get top unique three-grams\nfor item in item_names:\n    threegrams = top_unique_threegrams_by_item(df_4, item_name=item, n=10)\n    print(f\"Top unique three-grams for {item}:\")\n    print(\"Positive Threegrams:\", threegrams['top_positive_threegrams'])\n    print(\"Negative Threegrams:\", threegrams['top_negative_threegrams'])\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:53:52.150964Z","iopub.execute_input":"2024-11-05T01:53:52.151570Z","iopub.status.idle":"2024-11-05T01:54:12.521951Z","shell.execute_reply.started":"2024-11-05T01:53:52.151527Z","shell.execute_reply":"2024-11-05T01:54:12.518955Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop unique three-grams for Puppia Dog Harnesses:\nPositive Threegrams: [('love easy put', 3.3523849902914358), ('best harnes ever', 3.0), ('expected good harness', 3.0), ('fits great loved', 3.0), ('fits westie great', 3.0), ('good small dog', 3.0), ('love puppia products', 3.0), ('perfect fit chihuahua', 3.0), ('perfect fit schnorkie', 3.0), ('perfect puppy cute', 3.0)]\nNegative Threegrams: [('bog little one', 3.0), ('made pup itch', 3.0), ('size accurate return', 3.0), ('sooo small medium', 3.0), ('hates going head', 2.1213203435596424), ('medium smaller xsmall', 2.1213203435596424), ('ordered medium smaller', 2.1213203435596424), ('ordered xxl received', 2.1213203435596424), ('puppy hates going', 2.1213203435596424), ('sizing way way', 2.1213203435596424)]\n\n\nTop unique three-grams for KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count:\nPositive Threegrams: [('favorite kind bar', 4.173886101225232), ('love kind bars', 2.4753103452541168), ('favorite kind bars', 2.083808626751234), ('yummy great price', 2.0), ('flavor kind bars', 1.7467475590669144), ('careful sugar little', 1.7320508075688776), ('excellent careful sugar', 1.7320508075688776), ('sugar little one', 1.7320508075688776), ('good tasting good', 1.6848481568553884), ('great breakfast go', 1.6848481568553884)]\nNegative Threegrams: [('damages apple sauce', 1.0), ('kind bars stale', 1.0), ('received wrapper bar', 1.0), ('seemed bit stale', 1.0), ('stale hard fresh', 1.0), ('stale stale stale', 1.0), ('theyre rock hard', 1.0), ('bars received stale', 0.7071067811865476), ('unfortunately bars received', 0.7071067811865476), ('good hard rock', 0.6926995693345728)]\n\n\nTop unique three-grams for AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate:\nPositive Threegrams: [('easy put together', 4.794146241020286), ('sturdy easy assemble', 2.205347988403701), ('great great price', 1.4755051275626336), ('great price great', 1.362495167683398), ('crate great price', 1.310644489295656), ('sturdy well built', 1.1957402323414281), ('easy assemble great', 1.1589462121255412), ('easy assemble strong', 1.1416712637877284), ('crate well made', 1.1364323445637738), ('best bang buck', 1.0)]\nNegative Threegrams: [('boxer tore crate', 0.4472135954999579), ('lab boxer tore', 0.4472135954999579), ('month old lab', 0.4472135954999579), ('old lab boxer', 0.4472135954999579), ('tore crate apart', 0.4472135954999579), ('bend side escape', 0.4082482904638631), ('managed bend side', 0.4082482904638631), ('month old puppy', 0.4082482904638631), ('old puppy managed', 0.4082482904638631), ('puppy managed bend', 0.4082482904638631)]\n\n\n","output_type":"stream"}],"execution_count":113},{"cell_type":"code","source":"# Download required NLTK data if needed\nnltk.download(\"stopwords\")\nstop_words = set(stopwords.words(\"english\"))\ncustom_stop_words = list(stop_words.union({\"amazon\", \"com\", \"product\", \"video\", \"image\", \"hidden\", \"class\", \"name\", \"box\"}))\n\ndef top_unique_fourgrams_by_item(df, item_name, n=5):\n    \"\"\"\n    Extract the top unique positive and negative four-grams for a specific item in a dataset.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing the reviews.\n    - item_name (str): The item name to filter by.\n    - n (int): The number of top four-grams to return for positive and negative sentiment.\n    \n    Returns:\n    - dict: Unique top positive and negative four-grams for the specified item.\n    \"\"\"\n    \n    # Filter for the specified item\n    item_df = df[df['itemName'] == item_name]\n    \n    # Separate positive and negative reviews based on 'rating' values\n    positive_reviews = item_df[item_df['rating'].isin([4, 5])]['reviewText'].fillna(\"\")\n    negative_reviews = item_df[item_df['rating'].isin([1, 2])]['reviewText'].fillna(\"\")\n    \n    # Vectorize and remove stop words, using TF-IDF and four-grams (4-word phrases)\n    vectorizer = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(4, 4), max_df=0.85)\n    \n    # Positive four-grams frequency\n    positive_word_matrix = vectorizer.fit_transform(positive_reviews)\n    positive_word_counts = positive_word_matrix.sum(axis=0).A1\n    positive_fourgrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), positive_word_counts)}\n    top_positive_fourgrams = sorted(positive_fourgrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Negative four-grams frequency\n    negative_word_matrix = vectorizer.fit_transform(negative_reviews)\n    negative_word_counts = negative_word_matrix.sum(axis=0).A1\n    negative_fourgrams = {word: count for word, count in zip(vectorizer.get_feature_names_out(), negative_word_counts)}\n    top_negative_fourgrams = sorted(negative_fourgrams.items(), key=lambda x: x[1], reverse=True)[:n]\n    \n    # Remove overlapping four-grams to ensure uniqueness\n    positive_set = set(word for word, count in top_positive_fourgrams)\n    negative_set = set(word for word, count in top_negative_fourgrams)\n    \n    unique_positive_fourgrams = [(word, count) for word, count in top_positive_fourgrams if word not in negative_set]\n    unique_negative_fourgrams = [(word, count) for word, count in top_negative_fourgrams if word not in positive_set]\n    \n    return {\n        'top_positive_fourgrams': unique_positive_fourgrams[:n],\n        'top_negative_fourgrams': unique_negative_fourgrams[:n]\n    }\n\n# List of item names to analyze\nitem_names = [\n    \"Puppia Dog Harnesses\",\n    \"KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count\",\n    \"AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate\"\n]\n\n# Loop through each item and get top unique four-grams\nfor item in item_names:\n    fourgrams = top_unique_fourgrams_by_item(df_4, item_name=item, n=10)\n    print(f\"Top unique four-grams for {item}:\")\n    print(\"Positive Fourgrams:\", fourgrams['top_positive_fourgrams'])\n    print(\"Negative Fourgrams:\", fourgrams['top_negative_fourgrams'])\n    print(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:54:12.523637Z","iopub.execute_input":"2024-11-05T01:54:12.524050Z","iopub.status.idle":"2024-11-05T01:54:32.834175Z","shell.execute_reply.started":"2024-11-05T01:54:12.524010Z","shell.execute_reply":"2024-11-05T01:54:32.833005Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nTop unique four-grams for Puppia Dog Harnesses:\nPositive Fourgrams: [('bandit loves new swag', 3.0), ('brand harness buy pups', 3.0), ('dog loves sturdy comfortable', 3.0), ('easy put attachment sturdy', 3.0), ('fit 4lb teacup yorkie', 3.0), ('good would recommend friend', 3.0), ('great halter great price', 3.0), ('harness great dog bit', 3.0), ('looks works great bichon', 3.0), ('love boy like take', 3.0)]\nNegative Fourgrams: [('ordered medium smaller xsmall', 3.0), ('ordered xxl received small', 3.0), ('puppy hates going head', 3.0), ('sizing way way big', 3.0), ('described cat even wear', 2.1213203435596424), ('even though measured dog', 2.1213203435596424), ('fall apart first uses', 2.1213203435596424), ('fit even though measured', 2.1213203435596424), ('fit large dog tiny', 2.1213203435596424), ('harness runs much small', 2.1213203435596424)]\n\n\nTop unique four-grams for KIND Bars, Dark Chocolate Nuts &amp; Sea Salt, Gluten Free, 1.4 Ounce Bars, 12 Count:\nPositive Fourgrams: [('careful sugar little one', 2.1213203435596424), ('excellent careful sugar little', 2.1213203435596424), ('one favorite kind bar', 1.4876977256509636), ('favorite kind bar flavors', 1.2127231191244932), ('favorite flavor kind bars', 1.1675730794536856), ('caramel almond sea salt', 1.1242898823162717), ('best candy bar world', 1.0), ('bought gift laws love', 1.0), ('delicious 5g sugar mmmmm', 1.0), ('delicious crunchy salty sweet', 1.0)]\nNegative Fourgrams: [('unfortunately bars received stale', 1.0), ('bar hard compared varieties', 0.7071067811865476), ('bars stale rock hard', 0.7071067811865476), ('chocolate something else bland', 0.7071067811865476), ('good price going shopping', 0.7071067811865476), ('needs chocolate something else', 0.7071067811865476), ('package smashed bars un', 0.7071067811865476), ('peanut bar hard compared', 0.7071067811865476), ('price going shopping cart', 0.7071067811865476), ('smashed bars un eatable', 0.7071067811865476)]\n\n\nTop unique four-grams for AmazonBasics Single Door &amp; Double Door Folding Metal Dog Crate:\nPositive Fourgrams: [('easy put together perfect', 1.0707160128713042), ('put together perfect size', 1.0707160128713042), ('arrived quickly sturdy hoped', 1.0), ('bit smaller expected love', 1.0), ('bottom tray broken corner', 1.0), ('correct size 93lb lab', 1.0), ('easy assemble great quality', 1.0), ('easy assemble perfect description', 1.0), ('everything expected dog crate', 1.0), ('excellent quality value money', 1.0)]\nNegative Fourgrams: [('boxer tore crate apart', 0.5), ('lab boxer tore crate', 0.5), ('month old lab boxer', 0.5), ('old lab boxer tore', 0.5), ('managed bend side escape', 0.4472135954999579), ('month old puppy managed', 0.4472135954999579), ('old puppy managed bend', 0.4472135954999579), ('puppy managed bend side', 0.4472135954999579), ('strong month old puppy', 0.4472135954999579), ('3rd day 7month 70lb', 0.3535533905932738)]\n\n\n","output_type":"stream"}],"execution_count":114},{"cell_type":"code","source":"# Download stopwords\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Preprocessing function\ndef preprocess_text(text):\n    # Remove special characters and lowercase text\n    text = re.sub(r'\\W', ' ', str(text)).lower()\n    # Remove stopwords\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    return text\n\n# Assign sentiment labels based on 'rating'\ndef assign_sentiment_label(rating):\n    if rating in [4, 5]:\n        return 'positive'\n    elif rating in [1, 2]:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Preprocess reviewText and assign sentiment labels\ndf_4['processed_reviewText'] = df_4['reviewText'].fillna('').apply(preprocess_text)\ndf_4['sentiment'] = df_4['rating'].apply(assign_sentiment_label)\n\ndef evaluate_sentiment_model(df, verification_column):\n    \"\"\"\n    Train and evaluate a sentiment prediction model using a specific verification column.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing reviews and verification status.\n    - verification_column (str): The verification column to filter on ('Amazon_verified' or 'Amazon_verified_leverage').\n\n    Returns:\n    - Prints accuracy and classification report for the model trained on the filtered data.\n    \"\"\"\n    # Filter the data for rows where the specified verification column is 'Verified'\n    verified_df = df[df[verification_column] == 'Verified']\n\n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        verified_df['processed_reviewText'], verified_df['sentiment'], test_size=0.25, random_state=42\n    )\n\n    # Define and train the model\n    model = make_pipeline(CountVectorizer(), MultinomialNB())\n    model.fit(X_train, y_train)\n\n    # Make predictions and evaluate\n    y_pred = model.predict(X_test)\n    print(f\"Results for {verification_column} = Verified:\")\n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"\\n\")\n\n# Evaluate the model for both verification conditions\nevaluate_sentiment_model(df_4, verification_column=\"Amazon_verified\")\nevaluate_sentiment_model(df_4, verification_column=\"Amazon_verified_leverage\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:54:32.835436Z","iopub.execute_input":"2024-11-05T01:54:32.835800Z","iopub.status.idle":"2024-11-05T01:55:18.703200Z","shell.execute_reply.started":"2024-11-05T01:54:32.835764Z","shell.execute_reply":"2024-11-05T01:55:18.702161Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\nResults for Amazon_verified = Verified:\nAccuracy: 0.8601798313086839\nClassification Report:\n               precision    recall  f1-score   support\n\n    negative       0.65      0.43      0.52      7054\n     neutral       0.37      0.09      0.14      5542\n    positive       0.88      0.98      0.93     62808\n\n    accuracy                           0.86     75404\n   macro avg       0.64      0.50      0.53     75404\nweighted avg       0.82      0.86      0.83     75404\n\n\n\nResults for Amazon_verified_leverage = Verified:\nAccuracy: 0.8595892679695263\nClassification Report:\n               precision    recall  f1-score   support\n\n    negative       0.65      0.46      0.54      8734\n     neutral       0.35      0.09      0.15      6546\n    positive       0.89      0.97      0.93     75290\n\n    accuracy                           0.86     90570\n   macro avg       0.63      0.51      0.54     90570\nweighted avg       0.82      0.86      0.83     90570\n\n\n\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"# Download stopwords\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# Preprocessing function\ndef preprocess_text(text):\n    text = re.sub(r'\\W', ' ', str(text)).lower()  # Remove special characters and lowercase\n    return ' '.join([word for word in text.split() if word not in stop_words])\n\n# Assign sentiment labels based on 'rating'\ndef assign_sentiment_label(rating):\n    if rating in [4, 5]:\n        return 'positive'\n    elif rating in [1, 2]:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Preprocess reviewText and assign sentiment labels\ndf_4['processed_reviewText'] = df_4['reviewText'].fillna('').apply(preprocess_text)\ndf_4['sentiment'] = df_4['rating'].apply(assign_sentiment_label)\n\ndef evaluate_sentiment_model(df, verification_column):\n    \"\"\"\n    Train and evaluate a sentiment prediction model using Logistic Regression on a specific verification column.\n    \n    Parameters:\n    - df (DataFrame): The dataset containing reviews and verification status.\n    - verification_column (str): The verification column to filter on ('Amazon_verified' or 'Amazon_verified_leverage').\n\n    Returns:\n    - Prints accuracy and classification report for the model trained on the filtered data.\n    \"\"\"\n    # Filter the data for rows where the specified verification column is 'Verified'\n    verified_df = df[df[verification_column] == 'Verified']\n\n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        verified_df['processed_reviewText'], verified_df['sentiment'], test_size=0.25, random_state=42\n    )\n\n    # Define and train the Logistic Regression model\n    model = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=200, C=10))\n    model.fit(X_train, y_train)\n\n    # Make predictions and evaluate\n    y_pred = model.predict(X_test)\n    print(f\"Results for {verification_column} = Verified (Logistic Regression):\")\n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"\\n\")\n\n# Evaluate the model for both verification conditions\nevaluate_sentiment_model(df_4, verification_column=\"Amazon_verified\")\nevaluate_sentiment_model(df_4, verification_column=\"Amazon_verified_leverage\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:55:18.704563Z","iopub.execute_input":"2024-11-05T01:55:18.704916Z","iopub.status.idle":"2024-11-05T01:57:30.887466Z","shell.execute_reply.started":"2024-11-05T01:55:18.704881Z","shell.execute_reply":"2024-11-05T01:57:30.886404Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Results for Amazon_verified = Verified (Logistic Regression):\nAccuracy: 0.8566654288897141\nClassification Report:\n               precision    recall  f1-score   support\n\n    negative       0.61      0.50      0.55      7054\n     neutral       0.32      0.19      0.24      5542\n    positive       0.90      0.96      0.93     62808\n\n    accuracy                           0.86     75404\n   macro avg       0.61      0.55      0.57     75404\nweighted avg       0.83      0.86      0.84     75404\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Results for Amazon_verified_leverage = Verified (Logistic Regression):\nAccuracy: 0.8572706194104008\nClassification Report:\n               precision    recall  f1-score   support\n\n    negative       0.61      0.54      0.57      8734\n     neutral       0.30      0.18      0.23      6546\n    positive       0.91      0.95      0.93     75290\n\n    accuracy                           0.86     90570\n   macro avg       0.61      0.56      0.58     90570\nweighted avg       0.84      0.86      0.84     90570\n\n\n\n","output_type":"stream"}],"execution_count":116},{"cell_type":"code","source":"# Define the pipeline with CountVectorizer and Logistic Regression\npipeline = make_pipeline(CountVectorizer(), LogisticRegression())\n\n# Define the parameter grid\nparam_grid = {\n    'logisticregression__C': [0.01, 0.1, 1, 10, 100],   # Different levels of regularization strength\n    'logisticregression__max_iter': [100, 200, 500],     # Maximum iterations to ensure convergence\n}\n\n# Use GridSearchCV to find the best hyperparameters\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n\n# Fit the grid search on the training data (replace X_train and y_train with your data)\ngrid_search.fit(X_train, y_train)\n\n# Get the best model from grid search\nbest_model = grid_search.best_estimator_\n\n# Print the best hyperparameters found\nprint(\"Best Hyperparameters:\", grid_search.best_params_)\n\n# Evaluate the model with the best parameters on the test set\ny_pred = best_model.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T01:57:30.888753Z","iopub.execute_input":"2024-11-05T01:57:30.889110Z","iopub.status.idle":"2024-11-05T02:14:41.492124Z","shell.execute_reply.started":"2024-11-05T01:57:30.889075Z","shell.execute_reply":"2024-11-05T02:14:41.490200Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 15 candidates, totalling 75 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Best Hyperparameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 500}\nAccuracy: 0.8625353532524992\nClassification Report:\n               precision    recall  f1-score   support\n\n    negative       0.69      0.49      0.57     11033\n     neutral       0.42      0.12      0.19      7964\n    positive       0.89      0.98      0.93     88136\n\n    accuracy                           0.86    107133\n   macro avg       0.67      0.53      0.56    107133\nweighted avg       0.83      0.86      0.84    107133\n\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=100; total time=  23.7s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=200; total time=  24.5s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=200; total time=  25.9s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=500; total time=  26.1s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=100; total time=  30.2s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=200; total time=  48.4s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=500; total time=  50.3s\n[CV] END logisticregression__C=1, logisticregression__max_iter=100; total time=  30.0s\n[CV] END logisticregression__C=1, logisticregression__max_iter=100; total time=  30.3s\n[CV] END logisticregression__C=1, logisticregression__max_iter=200; total time=  47.2s\n[CV] END logisticregression__C=1, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=1, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=10, logisticregression__max_iter=200; total time=  47.8s\n[CV] END logisticregression__C=10, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=100, logisticregression__max_iter=100; total time=  29.6s\n[CV] END logisticregression__C=100, logisticregression__max_iter=100; total time=  29.9s\n[CV] END logisticregression__C=100, logisticregression__max_iter=200; total time=  47.3s\n[CV] END logisticregression__C=100, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=100; total time=  26.4s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=200; total time=  25.6s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=500; total time=  25.5s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=100; total time=  29.5s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=100; total time=  30.2s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=200; total time=  48.4s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=500; total time=  49.0s\n[CV] END logisticregression__C=1, logisticregression__max_iter=100; total time=  29.5s\n[CV] END logisticregression__C=1, logisticregression__max_iter=100; total time=  30.0s\n[CV] END logisticregression__C=1, logisticregression__max_iter=200; total time=  48.5s\n[CV] END logisticregression__C=1, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=10, logisticregression__max_iter=100; total time=  29.3s\n[CV] END logisticregression__C=10, logisticregression__max_iter=100; total time=  28.5s\n[CV] END logisticregression__C=10, logisticregression__max_iter=200; total time=  47.7s\n[CV] END logisticregression__C=10, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=10, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=100, logisticregression__max_iter=200; total time=  48.6s\n[CV] END logisticregression__C=100, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=100; total time=  24.2s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=100; total time=  25.0s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=200; total time=  24.5s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=500; total time=  25.7s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=100; total time=  29.4s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=200; total time=  48.8s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=200; total time=  49.3s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=500; total time=  47.0s\n[CV] END logisticregression__C=1, logisticregression__max_iter=100; total time=  29.6s\n[CV] END logisticregression__C=1, logisticregression__max_iter=200; total time=  48.2s\n[CV] END logisticregression__C=1, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=10, logisticregression__max_iter=100; total time=  29.2s\n[CV] END logisticregression__C=10, logisticregression__max_iter=100; total time=  29.2s\n[CV] END logisticregression__C=10, logisticregression__max_iter=200; total time=  47.5s\n[CV] END logisticregression__C=10, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=100, logisticregression__max_iter=100; total time=  29.2s\n[CV] END logisticregression__C=100, logisticregression__max_iter=100; total time=  29.3s\n[CV] END logisticregression__C=100, logisticregression__max_iter=200; total time=  47.7s\n[CV] END logisticregression__C=100, logisticregression__max_iter=200; total time=  46.0s\n[CV] END logisticregression__C=100, logisticregression__max_iter=500; total time= 1.6min\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=100; total time=  25.5s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=200; total time=  25.0s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=500; total time=  25.1s\n[CV] END logisticregression__C=0.01, logisticregression__max_iter=500; total time=  25.3s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=100; total time=  30.2s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=200; total time=  48.1s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=500; total time=  51.4s\n[CV] END logisticregression__C=0.1, logisticregression__max_iter=500; total time=  47.4s\n[CV] END logisticregression__C=1, logisticregression__max_iter=200; total time=  48.2s\n[CV] END logisticregression__C=1, logisticregression__max_iter=200; total time=  46.4s\n[CV] END logisticregression__C=1, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=10, logisticregression__max_iter=100; total time=  30.4s\n[CV] END logisticregression__C=10, logisticregression__max_iter=200; total time=  48.5s\n[CV] END logisticregression__C=10, logisticregression__max_iter=200; total time=  47.4s\n[CV] END logisticregression__C=10, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=100, logisticregression__max_iter=100; total time=  30.5s\n[CV] END logisticregression__C=100, logisticregression__max_iter=200; total time=  48.9s\n[CV] END logisticregression__C=100, logisticregression__max_iter=500; total time= 1.7min\n[CV] END logisticregression__C=100, logisticregression__max_iter=500; total time= 1.2min\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}